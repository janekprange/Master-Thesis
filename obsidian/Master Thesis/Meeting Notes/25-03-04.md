# Besprechungsnotizen

- Modelle funktionieren!
	- SFAM Accuracy zwischen 85% und 90%
	- LISA MSE < 0,1
	- Training ist schnell (zwischen 10 und 35 Minuten mit Early Return) - LISA etwas länger als SFAM
	- HPO dauert 4 bis 6 Stunden
	- Das generieren der SFAM Style Vektoren ist sehr langsam (768 * number of answers inferences), aber mir fällt keine Möglichkeit ein das schneller zu machen
		- automatic batching könnte eine Verbesserung sein, im Moment erstelle ich manuell Batches
		- -> VLLM
- neue Trainingsdaten (+val +test) für SFAM
	- pro Style Sentence (nicht Cluster) ein positives und ein negatives Sample
		- Auswahl nach der durchschnittlichen Similarity des Style Sentence zu allen Style Vector Attributes, die in der Answer vorkommen (die Style Vector Attributes sind geclustert)
		- Positives Sample muss mit dem Sentence beschrieben worden sein, negatives darf nicht damit beschrieben worden sein
	- Antworten sind getrennt nach train/validation/test
	- Style Sentences haben nur wenig Überschneidungen zwischen den verschiedenen Datensätzen, sind aber nicht explizit getrennt
		- Train:        244,144
		- Val:             74,400
		- Test:           38,781
		- All:           338,746
		- Control:   357,325 (train + val + test)
	- Wenn nicht alle Style Sentences verwendet werden, werden die mit der größten range zwischen positiven und negativen example gewählt
- filtere Antworten nach maximaler Länge beim Import
	- im Moment Grenze von 512 Token -> darauf werden die inputs von sfam und lisa auch gepadded/truncated
		- Stackex: Bucket 0-511: Sum = 171423 (98%)
		- Stackex: Bucket 512-767: Sum = 3149 (1.8%)
		- Stackex: Bucket 768-1023: Sum = 268 (0.15%)
		- Stackex: Bucket 1024-9998: Sum = 24 (0.014%)
		- Askx: Bucket 0-511: Sum = 18763 (100%)
		- Askx: Bucket 512-767: Sum = 1 (0.00533%)
		- Askx: Bucket 768-1023: Sum = 0 (0.00%)
		- Askx: Bucket 1024-9998: Sum = 0 (0.00%)
	- Grenze von Maximalanzahl an Worten entfernt (die hat vor den Zahlen oben gegriffen, die werden also noch anders sein)
- Idee für Experiment:
	- SFAM einmal auf Style + Knowledge Sentences trainieren und einmal nur auf Style Sentences trainieren; beide gegen Knowledge Sentences testen
		- Ich würde damit rechnen, dass es keinen großen Unterschied gibt, da der Hauptaspekt beim Training ist die Struktur des Inputs zu verstehen, das Sprachverständnis existiert ja bereits
- die Style Sentences mit Bezug zu Mathe sind nicht so zuverlässig
	- das Modell scheint dann öfter aussagen zu "wollen", dass überhaupt Mathe benutzt wird und achtet weniger auf die Feinheiten
		- The author uses the mathematical notation "|" to represent a quantity.
		- The author uses inconsistent mathematical notation.
	- eine Möglichkeit dagegen wäre eventuell, Cluster auszuschließen die nur von einer Gruppe verwendet werden
		- zur Unterscheidung der Gruppen würden Attribute verwendet werden, die mehrere Gruppen verwenden, aber verschieden stark ausgeprägt
		- das funktioniert allerdings sowieso nicht, wenn mehr als eine Gruppe viel Mathe benutzt
		- vielleicht ansonsten einen Absatz über diese Schwäche der Methodik schreiben
		- vielleicht wird es auch besser mit mehr Trainingsdaten (wobei SFAM jetzt schon weniger als eine Epoche lernt)
- Script geschrieben, um Sätze umzuformen für das Steering (zweite und dritte Methode)
	- von "The author uses ..." zu "You use ..."

## Fragen

- ich bin mir nicht sicher, wie das lisa style embedding erstellt wird
	- *We experiment with two different simple and interpretable embedding layers, a weight vector (w768) and a weight matrix (W768×64). We attach these on top of the LISA model and train just the layer using a contrastive learning objective and triplet loss*
	- Könnte das nicht auch ein eigenes sehr simples (lineares?) Modell sein, das den style vector in ein style embedding überführt?
- Gedanken machen zur manual Evaluation
	- Möglichkeit SFAM testen
		- Style Sentence und Text geben und sagen ob bzw. wie viel das passt (Likert Skala o.ä.)
		- das wurde in [[@patelLearningInterpretableStyle2023]] gemacht
	- Möglichkeit LISA testen
		- Texte von verschiedenen oder gleichen Gruppen geben und sagen ob sie zur gleichen Gruppe gehören
		- dafür braucht man wahrscheinlich kein Human Trial
	- -> lieber Steering manuell testen
- Für [STEL](https://github.com/nlpsoc/STEL) ist etwas mehr Arbeit nötig, um alle Daten zu bekommen, dann sollte es problemlos möglich sein

## HPO
### SFAM
![[img/newplot.png]]


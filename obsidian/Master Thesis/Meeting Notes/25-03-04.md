# Besprechungsnotizen

- neue Trainingsdaten (+val +test) für SFAM
	- pro Style Sentence (nicht Cluster) ein positives und ein negatives Sample
		- Auswahl nach der durchschnittlichen Similarity des Style Sentence zu allen Style Vector Attributes, die in der Answer vorkommen (die Style Vector Attributes sind geclustert)
		- Positives Sample muss mit dem Sentence beschrieben worden sein, negatives darf nicht damit beschrieben worden sein
	- Antworten sind getrennt nach train/validation/test
	- Style Sentences haben nur wenig Überschneidungen zwischen den verschiedenen Datensätzen
		- Train:        244,144
		- Val:             74,400
		- Test:           38,781
		- All:           338,746
		- Control:   357,325 (train + val + test)
	- Wenn nicht alle Style Sentences zum Trainieren verwendet werden sollen, gibt es im Moment keine besondere Auswahl, die Sentences werden einfach zufällig gewählt
		- möglich wäre eine Sortierung nach range zwischen Similarity von positiven und negativen Samples
- filtere Antworten nach maximaler Länge beim Import
	- im Moment Grenze von 512 Token
		- Stackex: Bucket 0-511: Sum = 171423 (98%)
		- Stackex: Bucket 512-767: Sum = 3149 (1.8%)
		- Stackex: Bucket 768-1023: Sum = 268 (0.15%)
		- Stackex: Bucket 1024-9998: Sum = 24 (0.014%)
		- Askx: Bucket 0-511: Sum = 18763 (100%)
		- Askx: Bucket 512-767: Sum = 1 (0.00533%)
		- Askx: Bucket 768-1023: Sum = 0 (0.00%)
		- Askx: Bucket 1024-9998: Sum = 0 (0.00%)
	- Grenze von Mindestanzahl an Worten entfernt (die hat vor den Zahlen oben gegriffen, die werden also noch anders sein)
- Idee für Experiment:
	- SFAM auf allen Sentences trainieren und nur auf Style Sentences trainieren; beide gegen Knowledge Sentences testen
- die Style Sentences mit Bezug zu Mathe sind nicht so zuverlässig
	- das Modell scheint dann öfter aussagen zu "wollen", dass überhaupt Mathe benutzt wird und achtet weniger auf die Feinheiten
		- The author uses the mathematical notation "|" to represent a quantity.
		- The author uses inconsistent mathematical notation.
	- eine Möglichkeit dagegen wäre eventuell, Cluster auszuschließen die nur von einer Gruppe verwendet werden
		- zur Unterscheidung der Gruppen würden Attribute verwendet werden, die mehrere Gruppen verwenden, aber verschieden stark ausgeprägt
		- das funktioniert allerdings sowieso nicht, wenn mehr als eine Gruppe viel Mathe benutzt
		- vielleicht ansonsten einen Absatz über diese Schwäche der Methodik schreiben
		- vielleicht wird es auch besser mit mehr Trainingsdaten (wobei SFAM jetzt schon weniger als eine Epoche lernt)
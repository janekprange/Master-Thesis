---
category: literaturenote
tags: [Computer_Science/Computation_and_Language, programming_library]
citekey: wolfHuggingFacesTransformersStateart2020
---
# HuggingFace's Transformers: State-of-the-art Natural Language Processing

> [!info]-
> **FirstAuthor**:: Wolf, Thomas  
> **Author**:: Debut, Lysandre  
> **Author**:: Sanh, Victor  
> **Author**:: Chaumond, Julien  
> **Author**:: Delangue, Clement  
> **Author**:: Moi, Anthony  
> **Author**:: Cistac, Pierric  
> **Author**:: Rault, Tim  
> **Author**:: Louf, RÃ©mi  
> **Author**:: Funtowicz, Morgan  
> **Author**:: Davison, Joe  
> **Author**:: Shleifer, Sam  
> **Author**:: Platen, Patrick von  
> **Author**:: Ma, Clara  
> **Author**:: Jernite, Yacine  
> **Author**:: Plu, Julien  
> **Author**:: Xu, Canwen  
> **Author**:: Scao, Teven Le  
> **Author**:: Gugger, Sylvain  
> **Author**:: Drame, Mariama  
> **Author**:: Lhoest, Quentin  
> **Author**:: Rush, Alexander M.  
> ---    
> **Title**:: HuggingFace's Transformers: State-of-the-art Natural Language Processing  
> **Year**:: 2020   
> **Citekey**:: wolfHuggingFacesTransformersStateart2020  
> **Type**:: preprint  
> **DOI**:: 10.48550/arXiv.1910.03771
> ---
> Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. \textit{Transformers} is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. \textit{Transformers} is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at \url{https://github.com/huggingface/transformers}.

## Notes
%% begin notes %%

%% end notes %%

## Annotations



%% Import Date: 2024-11-25T13:54:58.167+01:00 %%

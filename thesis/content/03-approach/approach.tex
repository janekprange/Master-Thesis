% !TeX root = ..\..\thesis.tex
\chapter{Approach}
\label{sec:approach}


\section{Data Collection}
\label{sec:approach:data_collection}


\section{Architecture and Models used}
\label{sec:approach:architecture_models}

\subsection{Architecture}
\label{sec:approach:architecture_models:architecture}

\begin{itemize}
  \item Style Sentence Generation
  \item Clustering
  \item Selection of Style Vector Attributes
  \item Training SFAM and LISA
  \item Training the embedding model
  \item Prompt Steering
  \item Activation Steering
\end{itemize}

\subsection{Models}
\label{sec:approach:architecture_models:models}

\begin{itemize}
  \item Llama3.2
  \item Sentence Transformer
  \item DeBERTaV3
  \item \ldots
\end{itemize}


\section{Evaluation Metrics}
\label{sec:approach:evaluation_metrics}

\begin{itemize}
  \item SFAM
        \begin{itemize}
          \item accuracy and F1 with regard to labels from select examples of the style sentence generation (was the sentence used or not)
        \end{itemize}
  \item LISA
        \begin{itemize}
          \item MSE, MAE, avg. cosine similarity compared to SFAM prediction
          \item accuracy and F1 compared to SFAM where both predictions are rounded
        \end{itemize}
  \item embedding model
        \begin{itemize}
          \item accuracy through triplet loss
                %? \item variance inside groups
        \end{itemize}
  \item steering methods
        \begin{itemize}
          \item improvement of L2 distance to group median compared to embedding of unsteered generation
                \begin{itemize}
                  \item how strong is the steering?
                \end{itemize}
          \item cosine similarity between the vector that is the difference between embedding of steered and unsteered generation
                \begin{itemize}
                  \item is the steering in the correct direction?
                \end{itemize}
                %? \item the absolute times that the resulting group is the correct one (according to the embedding)
        \end{itemize}
\end{itemize}


\section{Style Sentence Generation}
\label{sec:approach:style_sentence_generation}

The style sentences that form the dimensions of the interpretable style vector are generated by prompting a \acl{llm} in a two-step procedure.

For step one, the \ac{llm} is presented with a zero-shot prompt to produce a description of the text. This step is repeated 92 times, each time with a different prompt that focuses on a specific aspect of the text. 6 prompts are relatively open and only give a loose direction on which style should be described by the model. 84 prompts are targeted towards an explicit stylistic feature. These prompts follow the work of \citet{patelLearningInterpretableStyle2023,tausczikPsychologicalMeaningWords2010} to get the model to focus on a broad variety of style that is important for the study of language.

In addition to these prompts aimed at stylistic features, there are two prompts which are focusing on the knowledge and experience of the author. While the background knowledge of the author is not as important for the group membership detection as the style of the text, it is helpful information for the steering task that is covered in later sections.

After generating the style descriptions, the \ac{llm} is prompted a second time to rewrite the description as a list of sentences. The model is instructed to write each sentence in a consistent form like \enquote{The author is \ldots} or \enquote{The author uses \ldots}.

Furthermore, the model is instructed to avoid negations and examples since these both lead to increasing problems with the clustering process that is described in Section~\ref{sec:approach:clustering}.
Sentences that include examples are potentially problematic because it increases the likelihood of sentences which have the exact same content while being of different shape. % TODO: better wording
Two sentences which differ only in the example are \enquote{The author uses filler words'} and \enquote{The author uses filler words such as 'and', 'or' and 'furthermore'}. While this problem will be reduced by clustering similar sentences, this procedure is not perfect and will be more robust if the model avoids sentences with examples.

Negations on the other hand lead to the problem where the shape of the sentences will be too close while the content is very different. There is a high chance that the sentences \enquote{The author does use long sentences} and \enquote{The author does not use long sentences} will be clustered together because so much of them is the same even though they state the opposite of each other.
Additionally, the dimensions of the final style vector should not include any negated attributes since the expression \enquote{The author uses short sentences} is much clearer than \enquote{The author does not use long sentences}.

Since the model might produce sentences with negations or examples despite the prompt, each of the generated sentences is checked automatically.

Per description, each distinct style sentence is recorded only once, even if the model generates it multiple times. This is done in case the model generates a bad answer where one sentence is repeated many times.

The whole process can be seen in Figure~\ref{fig:style_sentence_generation}.

\begin{figure}[ht]
  \input{figures/tikz/style_sentence_generation.tex}
  % TODO: better caption
  \caption{The process to generate style sentences.}
  \label{fig:style_sentence_generation}
\end{figure}


\section{Clustering}
\label{sec:approach:clustering}
A strength of the method to create style sentences described in Section~\ref{sec:approach:style_sentence_generation} is the lack of constraints which results in a large variety of generated sentences. However, this leads to the problem that sentences with the same content can have many different forms. An example for this would be the sentences \enquote{The author uses short and concise sentences.} and \enquote{The author uses concise and short sentences.}, which have exactly the same meaning while having a distinct form.

Since the approach up to this point only checked if sentences are exactly identical, it is more difficult to compare different input texts and to find texts that are an example of a specific style sentence. Additionally, it could be that a sentence would be a good attribute for the style sentence but is not selected by the algorithm described in Section~\ref{sec:approach:selection} because it is used with many different variations.
To solve this problem, my approach includes clustering the sentences by the cosine similarity of their embeddings with a sentence embedding model. % TODO: citation for the model (and name?)

The clustering algorithm first computes a radius neighbor graph of all sentences where sentences which have a cosine similarity of more than \minCosineSimilarity{}. Subsequently, the clusters are sorted by size and all sentences that have been included in a larger cluster are deleted from all smaller clusters to ensure that each sentence is only included in one cluster. At the same time, it has to be ensured that no sentence is left out of every cluster because for further approaches, the clusters are the relevant data.

For the resulting clusters, the style sentence that is closest to the center is the representative sentence of the whole cluster.


% \begin{itemize}
%   \item often, style sentences are generated that are very similar
%   \item e.g. \enquote{The author uses short and concise sentences.} and \enquote{The author uses concise and short sentences.}
%   \item If one style sentence is used very often but in many different variations, it may not get selected for the style sentence vector because each variation by itself has not occured often enough
%   \item The sentences are embedded with the model x % TODO: write that here?
%   \item because of that, all style sentences are clustered so that sentences which embeddings have a cosine distance of less than 0.15 count as the same sentence. The sentence that is closest to the center functions as the representation of the whole cluster
%   \item each sentence can only be in one cluster; if it is in multiple clusters it is removed from all but the largest
%   \item each sentence has to be in exactly one clusters, so many clusters include only one sentence
% \end{itemize}


\section{Selecting the Style Vector Attributes}
\label{sec:approach:selection}

\begin{itemize}
  \item the vector has \styleVectorSize{} dimensions, a large part (more than \SI{80}{\percent}) of the attributes are selected automatically
        \begin{itemize}
          \item the first \numTargetPrompts{} prompts are the clusters that are the closest to the target prompt. This follows the work of \citet{patelLearningInterpretableStyle2023}
          \item the next \minNumKnowledgePrompts{} prompts are knowledge prompts. The actual number can be more or less than that depending on the rest of the selection process. % explanation?
        \end{itemize}
  \item a cluster may only be used in a maximum of \clusterMaxGroupRatio{} of the groups
        \begin{itemize}
          \item otherwise it is not well suited to distinguish between the groups
          \item often, the same attribute was used multiple times to describe the same input text
                \begin{itemize}
                  \item multiple prompts produce the same attribute
                  \item if one prompt produces one attribute multiple times, it is only saved one time
                  \item for further computation, for each input text, each attribute is counted only once
                \end{itemize}
        \end{itemize}
  \item for all remaining remaining clusters, the number of answers it has to be used in is increased until a maximum of \maxClustersFirstSelection{} is left
  \item next, the similarity between all remaining clusters is computed and, in order of occurance, clusters that have a cosine similarity higher than \maxCosineSimilarity{} are removed from the selected
  \item final selection
        \begin{itemize}
          \item compute similarities between clusters selected at this stage
          \item for all clusters, compute the average similarity of all input texts by looking at the clusters that have been used to describe that input text
          \item sort sort the clusters by the difference between the most and least matching input text
          \item select the clusters with the highest difference
          \item this is done because a style attribute will probably hold more meaningful information and is better suited to differentiate texts if it is very similar to some and very dissimilar to other texts
        \end{itemize}
\end{itemize}


\section{Training and Testing \acs{sfam}}
\label{sec:approach:sfam}

\begin{itemize}
  \item \ac{sfam} is a model that takes a style sentence and a text as input and produces an agreement score
  \item training data
        \begin{itemize}
          % \item the \numStyleSentences{} style sentences are used for training % do not use numbers for approach
          \item there are distinct sets of input texts for training, validation and test datasets
          \item these lead to mostly different sentences (also the differences may be small)
          \item of all sentences, the best are selected
                \begin{itemize}
                  \item compute similarity to all style vector attributes (which are clusters)
                  \item for each sentence, compute the most similar and most dissimilar input text according to the average similarity to all style attributes that have been used to describe that text (like the final selection of style vector attributes, see Section~\ref{sec:approach:selection}) % TODO: is there a more specific reference to a subsection?
                  \item if one of the ten most similar input texts was actually described by the style sentence, it is chosen as a positive training sample and the least similar input text that was not described by the sentence as a negative sample
                  \item otherwise, the sentence is not used for training
                  \item the same is done for validation and test
                \end{itemize}
        \end{itemize}
  \item \ac{sfam} is a finetuned DeBERTaV3 model
        \begin{itemize}
          \item two fully connected layers with a ReLu in between % TODO: look up
          \item finally a sigmoid activation function to produce values between 0 and 1
        \end{itemize}
  \item optional hyperparameter optimization (with optuna -> citation?) to discover optimal learning rate and weight decay
  \item early stopping callback with patience of three
  \item validation metric of accuracy
  \item testing metric accuracy and f1
\end{itemize}


\section{Training and Testing \acs{lisa}}
\label{sec:approach:lisa}
\begin{itemize}
  \item to get values for a style vector, the \styleVectorSize{} forward passes by \ac{sfam} would take too long for most practical applications
  \item train an additional model that creates the whole vector in one forward pass
  \item \ac{lisa} like \ac{sfam} is a finetuned DeBERTaV3 model
        \begin{itemize}
          \item two fully connected layers with a ReLu in between % TODO: look up
          \item finally a sigmoid activation function to produce values between 0 and 1
        \end{itemize}
\end{itemize}

\section{Embedding Model}
\label{sec:approach:embedding}


\section{Possible Improvement through Knowledge Attributes}
\label{sec:approach:knowledge_attributes}


\section{Steering Text Generation with Simple Prompting}
\label{sec:approach:steering:simple}


\section{Steering Text Generation with Targeted Prompting}
\label{sec:approach:steering:targeted}


\section{Steering Text Generation with Activation Layer Manipulation}
\label{sec:approach:steering:actAdd}

\subsubsection{Extracting Steering Vectors}

\subsubsection{Generation Steering}
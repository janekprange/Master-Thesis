% !TeX root = ..\..\thesis.tex
\chapter{Approach}
\label{sec:approach}


\section{Data Collection}
\label{sec:approach:data_collection}


\section{Architecture and Models used}
\label{sec:approach:architecture_models}

\subsection{Architecture}
\label{sec:approach:architecture_models:architecture}

\begin{itemize}
  \item Style Sentence Generation
  \item Clustering
  \item Selection of Style Vector Attributes
  \item Training SFAM and LISA
  \item Training the embedding model
  \item Prompt Steering
  \item Activation Steering
\end{itemize}

\subsection{Models}
\label{sec:approach:architecture_models:models}

\begin{itemize}
  \item Llama3.2
  \item Sentence Transformer
  \item DeBERTaV3
  \item \ldots
\end{itemize}


\section{Evaluation Metrics}
\label{sec:approach:evaluation_metrics}

\begin{itemize}
  \item SFAM
        \begin{itemize}
          \item accuracy and F1 with regard to labels from select examples of the style sentence generation (was the sentence used or not)
        \end{itemize}
  \item LISA
        \begin{itemize}
          \item MSE, MAE, avg. cosine similarity compared to SFAM prediction
          \item accuracy and F1 compared to SFAM where both predictions are rounded
        \end{itemize}
  \item embedding model
        \begin{itemize}
          \item accuracy through triplet loss
                %? \item variance inside groups
        \end{itemize}
  \item steering methods
        \begin{itemize}
          \item improvement of L2 distance to group median compared to embedding of unsteered generation
                \begin{itemize}
                  \item how strong is the steering?
                \end{itemize}
          \item cosine similarity between the vector that is the difference between embedding of steered and unsteered generation
                \begin{itemize}
                  \item is the steering in the correct direction?
                \end{itemize}
                %? \item the absolute times that the resulting group is the correct one (according to the embedding)
        \end{itemize}
\end{itemize}


\section{Style Sentence Generation}
\label{sec:approach:style_sentence_generation}

The style sentences that form the dimensions of the interpretable style vector are generated by prompting a \acl{llm} in a two-step procedure.

For step one, the \ac{llm} is presented with a zero-shot prompt to produce a description of the text. This step is repeated 92 times, each time with a different prompt that focuses on a specific aspect of the text. 6 prompts are relatively open and only give a loose direction on which style should be described by the model. 84 prompts are targeted towards an explicit stylistic feature. These prompts follow the work of \citet{patelLearningInterpretableStyle2023,tausczikPsychologicalMeaningWords2010} to get the model to focus on a broad variety of style that is important for the study of language.

In addition to these prompts aimed at stylistic features, there are two prompts which are focusing on the knowledge and experience of the author. While the background knowledge of the author is not as important for the group membership detection as the style of the text, it is helpful information for the steering task that is covered in later sections.

After generating the style descriptions, the \ac{llm} is prompted a second time to rewrite the description as a list of sentences. The model is instructed to write each sentence in a consistent form like \enquote{The author is \ldots} or \enquote{The author uses \ldots}.

Furthermore, the model is instructed to avoid negations and examples since these both lead to increasing problems with the clustering process that is described in Section~\ref{sec:approach:clustering}.
Sentences that include examples are potentially problematic because it increases the likelihood of sentences which have the exact same content while being of different shape. % TODO: better wording
Two sentences which differ only in the example are \enquote{The author uses filler words} and \enquote{The author uses filler words such as 'and', 'or' and 'furthermore'}. While this problem will be reduced by clustering similar sentences, this procedure is not perfect and will be more robust if the model avoids sentences with examples.

Negations on the other hand lead to the problem where the shape of the sentences will be too close while the content is very different. There is a high chance that the sentences \enquote{The author does use long sentences} and \enquote{The author does not use long sentences} will be clustered together because so much of them is the same even though they state the opposite of each other.
Additionally, the dimensions of the final style vector should not include any negated attributes since the expression \enquote{The author uses short sentences} is much clearer than \enquote{The author does not use long sentences}.

Since the model might produce sentences with negations or examples despite the prompt, each of the generated sentences is checked automatically.

Per description, each distinct style sentence is recorded only once, even if the model generates it multiple times. This is done in case the model generates a bad answer where one sentence is repeated many times.

The whole process can be seen in Figure~\ref{fig:style_sentence_generation}.

\begin{figure}[ht]
  \input{figures/tikz/style_sentence_generation.tex}
  % TODO: better caption
  \caption{The process to generate style sentences.}
  \label{fig:style_sentence_generation}
\end{figure}


\section{Clustering}
\label{sec:approach:clustering}
A strength of the method to create style sentences described in Section~\ref{sec:approach:style_sentence_generation} is the lack of constraints which results in a large variety of generated sentences. However, this leads to the problem that sentences with the same content can have many different forms. An example for this would be the sentences \enquote{The author uses short and concise sentences.} and \enquote{The author uses concise and short sentences.}, which have exactly the same meaning while having a distinct form.

Since the approach up to this point only checked if sentences are exactly identical, it is more difficult to compare different input texts and to find texts that are an example of a specific style sentence. Additionally, it could be that a sentence would be a good attribute for the style sentence but is not selected by the algorithm described in Section~\ref{sec:approach:selection} because it is used with many different variations.
To solve this problem, my approach includes clustering the sentences by the cosine similarity of their embeddings with a sentence embedding model. % TODO: citation for the model (and name?)

The clustering algorithm first computes a radius neighbor graph of all sentences where sentences which have a cosine similarity of more than \num{\minCosineSimilarity{}}. Subsequently, the clusters are sorted by size and all sentences that have been included in a larger cluster are deleted from all smaller clusters to ensure that each sentence is only included in one cluster. At the same time, it has to be ensured that no sentence is left out of every cluster because for further approaches, the clusters are the relevant data.

For the resulting clusters, the style sentence that is closest to the center is the representative sentence of the whole cluster.

The size of the resulting synthetic dataset after clustering can be found in table~\ref{table:synthetic_dataset}.

\begin{table}
  \begin{center}
    % TODO: alignment of numbers inside the \num command
    \begin{tabular}{lS}
      \toprule
                   & {Number of data points}        \\ \midrule
      Answers      & \num{\numAnswersStyleVector{}} \\
      Prompts      & \numPrompts{}                  \\
      Descriptions & \numStyleDescriptions{}        \\
      Sentences    & \numStyleSentences{}           \\
      Clusters     & \num{\numClusters{}}           \\ \bottomrule
    \end{tabular}
    \caption{The number of answers and prompts used to create the synthetic dataset and the size of the resulting dataset.}
    \label{table:synthetic_dataset}
  \end{center}
\end{table}


% \begin{itemize}
%   \item often, style sentences are generated that are very similar
%   \item e.g. \enquote{The author uses short and concise sentences.} and \enquote{The author uses concise and short sentences.}
%   \item If one style sentence is used very often but in many different variations, it may not get selected for the style sentence vector because each variation by itself has not occured often enough
%   \item The sentences are embedded with the model x % TODO: write that here?
%   \item because of that, all style sentences are clustered so that sentences which embeddings have a cosine distance of less than 0.15 count as the same sentence. The sentence that is closest to the center functions as the representation of the whole cluster
%   \item each sentence can only be in one cluster; if it is in multiple clusters it is removed from all but the largest
%   \item each sentence has to be in exactly one clusters, so many clusters include only one sentence
% \end{itemize}


\section{Selecting the Style Vector Attributes}
\label{sec:approach:selection}

Following the previous steps, there is now a synthetic dataset with \num{\numClusters{}} that describe \num{\numAnswersStyleVector{}} answers by \num{\numGroups{}}. Since the final style vector will only consist of \num{\styleVectorSize{}} attributes, a process to select the best attributes is needed. This selection is carried out in multiple steps.

\subsection{Selection of target attributes}
\label{sec:approach:selection:target_attributes}
Following the work of \citet{patelLearningInterpretableStyle2023}, the first \num{\numTargetPrompts{}} attributes of the style vector will be selected to correspond to the \num{\numTargetPrompts{}} target prompts which were described in section~\ref{sec:approach:style_sentence_generation}.
This is done to ensure that the style vector has a robust foundation on some features that are manually selected for being relevant for stylistic research. The ability to automatically create most of the style vector is not reduced since the target attributes only account for around \SI{10}{\percent} of its size.

These attributes are found by creating sentences of the form \enquote{The author uses <target>} and embedding using the SentenceTransformer Model. % TODO: correct name
Afterward, for each sentence the style cluster with the highest cosine similarity is found.
All clusters that have been chosen this way to represent the
% TODO: find a nice final sentence

\subsection{Step 2}
% \label{} TODO:
An important characteristic of all attributes that are part of the style vector is that they are as meaningful as possible and helpful to distinguish different groups. Because of that, this step in the cluster selection ensures that only clusters which are used to describe texts by less than \clusterMaxGroupRatio{} of the groups are selected. The cutoff ratio of groups follows the work of \citet{patelLearningInterpretableStyle2023}.

For the next steps of the cluster selection, it is also important that there are not too many possible clusters to select from, otherwise the computation would need too much time and memory. To quickly reduce the number of clusters, the number of times the cluster was used to describe answers is taken into account. The required number of times used is increased until the resulting number of clusters is smaller than \num{\maxClustersFirstSelection}. This number was chosen to be small enough for the following computation but big enough to enable a meaningful selection of style vector attributes.

% TODO: include this?
A cluster could be used multiple times to describe the same answer. Although the sentence produced by each prompt is only counted once per prompt, multiple prompts could use the same or similar enough sentences to describe the answer. For this selection however, only the number of answers that have been described with the cluster are being counted and not how often the cluster was being used.

\subsection{Step 3}
% \label{} TODO:
To ensure that the style vector covers a wide range of attributes, it is important that the attributes do not cover too similar topics. This selection step fulfills this requirement by ensuring that the style vector attributes have a maximum cosine similarity of \num{\maxCosineSimilarity{}}. This process works by ordering the clusters by occurance, selecting them one after the other and deleting all clusters that are too close to the ones that have already been selected.

In the work by \citeauthor{patelLearningInterpretableStyle2023}, they use a maximum cosine similarity of \num{0.8} as a cutoff. I decided to use a lower maximum similarity to increase the variance of the style vector attribute and because of the clusters. % TODO: better explanation

\subsection{Step 4}
% \label{} TODO:
The first \num{\numTargetPrompts{}} attributes of the style vector are the target attributes that were selection in Section~\ref{sec:approach:selection:target_attributes}. The next \num{\minNumKnowledgePrompts{}} attributes are knowledge clusters, that is clusters of sentences that were produced by knowledge prompts. The rest of the style attributes are selected in this step to be the ones with the highest range of accordance. % TODO: better word than accordance?

Range of accordance means that the range between the answers that match the attribute really well and the ones that do not match is as big as possible. This further increases the probability that the attributes are well suited to distinguish between different answers and groups.

First of all, the similarity between all clusters that remain after the first selection steps are computed. Afterwards, the for each cluster and each answer the average similarity to all other clusters that have been used to describe that answer is computed. TODO:


\begin{itemize}
  \item \minNumKnowledgePrompts{} knowledge clusters are selected
  \item compute similarities between clusters selected at this stage
  \item for all clusters, compute the average similarity of all input texts by looking at the clusters that have been used to describe that input text
  \item sort the clusters by the difference between the most and least matching input text
  \item select the clusters with the highest difference
  \item this is done because a style attribute will probably hold more meaningful information and is better suited to differentiate texts if it is very similar to some and very dissimilar to other texts
\end{itemize}


\section{Training and Testing \acs{sfam}}
\label{sec:approach:sfam}

\begin{itemize}
  \item \ac{sfam} is a model that takes a style sentence and a text as input and produces an agreement score
  \item training data
        \begin{itemize}
          % \item the \numStyleSentences{} style sentences are used for training % do not use numbers for approach
          \item there are distinct sets of input texts for training, validation and test datasets
          \item these lead to mostly different sentences (also the differences may be small)
          \item of all sentences, the best are selected
                \begin{itemize}
                  \item compute similarity to all style vector attributes (which are clusters)
                  \item for each sentence, compute the most similar and most dissimilar input text according to the average similarity to all style attributes that have been used to describe that text (like the final selection of style vector attributes, see Section~\ref{sec:approach:selection}) % TODO: is there a more specific reference to a subsection?
                  \item if one of the ten most similar input texts was actually described by the style sentence, it is chosen as a positive training sample and the least similar input text that was not described by the sentence as a negative sample
                  \item otherwise, the sentence is not used for training
                  \item the same is done for validation and test
                \end{itemize}
        \end{itemize}
  \item \ac{sfam} is a finetuned DeBERTaV3 model
        \begin{itemize}
          \item two fully connected layers with a ReLu in between % TODO: look up
          \item finally a sigmoid activation function to produce values between 0 and 1
        \end{itemize}
  \item optional hyperparameter optimization (with optuna -> citation?) to discover optimal learning rate and weight decay
  \item early stopping callback with patience of three
  \item validation metric of accuracy
  \item testing metric accuracy and f1
\end{itemize}


\section{Training and Testing \acs{lisa}}
\label{sec:approach:lisa}
\begin{itemize}
  \item to get values for a style vector, the \num{\styleVectorSize{}} forward passes by \ac{sfam} would take too long for most practical applications
  \item train an additional model that creates the whole vector in one forward pass
  \item \ac{lisa} like \ac{sfam} is a finetuned DeBERTaV3 model
        \begin{itemize}
          \item two fully connected layers with a ReLu in between % TODO: look up
          \item finally a sigmoid activation function to produce values between 0 and 1
        \end{itemize}
\end{itemize}

\section{Embedding Model}
\label{sec:approach:embedding}


\section{Possible Improvement through Knowledge Attributes}
\label{sec:approach:knowledge_attributes}


\section{Steering Text Generation with Simple Prompting}
\label{sec:approach:steering:simple}


\section{Steering Text Generation with Targeted Prompting}
\label{sec:approach:steering:targeted}


\section{Steering Text Generation with Activation Layer Manipulation}
\label{sec:approach:steering:actAdd}

\subsubsection{Extracting Steering Vectors}

\subsubsection{Generation Steering}
\chapter{Introduction}
\label{sec:introduction}
Textual information plays a crucial role in daily life, appearing in various contexts, such as educational environments, news articles, entertainment media, and social media platforms. As noted in \citet{wegmannSameAuthorJust2022}, an important aspect of text is not only the message it conveys, but also the style in which it is presented. The style of a text significantly influences its reception, shaping how effectively the message is understood and how well it is accepted by the audience.

Stylistic features also serve analytical purposes; for instance, they can be used to identify the author of a text, as shown in \citet{alshomaryLatentSpaceInterpretation2024}, or to attribute the text to a particular group of individuals, as demonstrated by \citet{10.1007/978-3-642-29047-3_27}. Previous work, such as that of \citet{zhu-etal-2024-styleflow, ijcai2020p526, wegmannSameAuthorJust2022}, has highlighted the importance of style in textual analysis.

However, automating stylistic investigations with machine learning poses several challenges. One significant issue is the complexity and time-consuming nature of manual style annotations. Additionally, it is difficult to generate parallel datasets that include positive and negative examples for each stylistic label.

Because supervised learning methods rely on annotated data for training, state-of-the-art style representation methods tend to use unsupervised learning techniques. % TODO: citation
While effective, these methods often produce style embeddings that are difficult to interpret, which makes it harder to verify their quality and apply them to other tasks effectively.

To address these limitations, this thesis introduces interpretable attribute vectors based on the methodology proposed by \citet{patelLearningInterpretableStyle2023}. Figure~\ref{fig:attributeVector} illustrates the composition of these vectors. Each dimension of the vector corresponds to a real-world concept, and the associated value, ranging from \num{0} to \num{1}, indicates the extent to which a text aligns with the specified attribute.

\begin{figure}[ht]
      \begin{center}
            \input{content/01-introduction/attribute-vector-tikz.tex}
            \caption{An example of a \num{\styleVectorSize}-dimensional attribute vector that was generated with the method presented in this thesis.}% % TODO: more caption?
            \label{fig:attributeVector}
      \end{center}
\end{figure}

While state-of-the-art methods primarily focus on stylistic features for tasks such as authorship attribution, as shown in works by \citet{alshomaryLatentSpaceInterpretation2024, patelLearningInterpretableStyle2023, konenStyleVectorsSteering2024, zhu-etal-2024-styleflow}, other types of author-related attributes can complement these stylistic analyses. One such attribute is the author's background knowledge or experience, referred to as knowledge attributes. % TODO: why is knowledge important? citation
The interpretable attribute vector developed in this thesis therefore includes both stylistic and knowledge-related dimensions.

In addition to their relevance in tasks such as authorship attribution, group membership detection, or text classification more generally, these representations are also applicable in text generation, which is one of the most prominent applications in contemporary natural language processing. \Acp{llm}, which are based on the transformer architecture as introduced in \citet{NIPS2017_3f5ee243}, are widely used tools for generating natural language text. In recent years, \acp{llm} have been used for a wide range of tasks, including providing explanations for various topics and concepts.

As more users depend on \acp{llm}, new challenges emerge beyond ensuring the factual correctness of the generated explanations. One such challenge involves tailoring the language and conceptual content of the explanation to suit the linguistic style and background knowledge of the target audience. For instance, an explanation suitable for a Ph.D. student might be inappropriate for a middle school student, and vice versa. Style and knowledge representations can be instrumental in aligning the linguistic output with the expectations and comprehension levels of different user groups to produce the best explanations for all audiences.


\section{Problem Statement}
\label{sec:introduction:problemStatement}
Previous research has demonstrated that existing methods are highly effective for authorship attribution tasks. These approaches identify and distinguish individual writing styles, enabling the attribution of anonymous texts to specific authors with a high degree of accuracy. However, the goal of this thesis is to adapt and extend these techniques to address a related yet distinct challenge: group membership detection.

Though similar in concept, group membership detection differs from authorship attribution in significant ways. Like authorship attribution, group membership detection relies on distinguishing characteristics in the way texts are written. Groups often exhibit unique stylistic features that can serve as indicators of group identity. However, the underlying data structure presents a key distinction. Authorship attribution typically involves many authors, each of whom contributes a small number of texts. In contrast, group membership detection usually involves only a few groups, each of which provides a relatively large volume of textual data. This fundamental difference in data composition requires new approaches tailored specifically to group detection.

\researchQuestion{rq:interpretableGroupDetect}{How well are the interpretable style representations suited to detect the group membership of different authors?}

To investigate this question, this thesis extends the interpretable style representation model proposed by \citet{patelLearningInterpretableStyle2023}. The extension involves augmenting the existing style vector with additional knowledge-based attributes. These attributes capture essential information such as the experience level and background knowledge of the authors, which are factors that can vary significantly between groups. As these knowledge characteristics influence how individuals express ideas in writing, their inclusion has the potential to enhance the model's ability to differentiate between groups.

\researchSubQuestion{rq:interpretableGroupDetect:knowledgeAttributes}{Does the interpretable style representation benefit from knowledge attributes in addition to style attributes?}

While the task of detecting group membership is valuable in itself, as \aclp{llm} are becoming more popular, the ability to use them to generate group-specific explanations has gained increasing relevance. \acp{llm} are used in many applications to explain concepts to a large variety of groups of people. While the factual correctness of these explanations is important, the comprehensibility of the explanation is increased if the model can reflect the style and background knowledge of the recipient of the explanation. This thesis compares different steering methods and how the interpretable attribute vector that is presented in the first part of the thesis can contribute to existing methods for steering \ac{llm} outputs to better align with group-specific characteristics.

\researchQuestion{rq:generateExplanation}{What is the best way to generate group-specific explanations from style representations?}

To address this question, several steering methods for \acp{llm} will be examined. The initial focus will be on system prompt engineering, a widely used and accessible method for influencing model behavior. In particular, the thesis explores how the interpretable attribute vector can be used to guide the construction of system prompts that produce group-specific outputs. This includes formulating prompts to include dimensions of the interpretable attribute vector that are particularly relevant to a specific group.

\researchSubQuestion{rq:generateExplanation:attributeVector}{Can the attribute vector presented in this thesis be used to improve existing steering methods that change the system prompt?}

Despite its popularity, steering through system prompt modification has the limitation that it does not allow for fine-grained control over the steering. While it can guide the model in a general direction, it lacks the capacity to precisely modulate the strength of the steering effect.

To overcome this limitation, this thesis introduces a novel method for fine-grained steering that manipulates the activation space of the \ac{llm}. This technique involves altering the model's internal representations after specific layers, steering the activations toward particular conceptual directions that correspond to the dimensions of the interpretable attribute vector. This method builds upon recent research in activation-based model manipulation, including the work of \citet{konenStyleVectorsSteering2024,turnerActivationAdditionSteering2024,rimsky-etal-2024-steering}.

\researchSubQuestion{rq:generateExplanation:activation}{Can the newly proposed method of steering \iac{llm} by manipulating its activation space be used to improve existing steering methods?}


\section{Goals of the thesis}
\label{sec:introduction:goals}
\newlength{\maxstretch}
\setlength{\maxstretch}{0pt plus 1fill}
This thesis is guided by the research questions defined in Section~\ref{sec:introduction:problemStatement} and describes a continuous process that begins with preparing input data and ends with generating group-specific outputs from a steered model. Each goal contributes to the development of a framework for identifying group membership and steering language model behavior accordingly.

\begin{description}
      \item[Automatic Creation of an Annotated Synthetic Dataset]
            Annotating a large text corpus with diverse style and knowledge attributes is a difficult and time-consuming task. This challenge is amplified by the need for diverse attributes that are not bound to predefined topics. To address this issue, the first goal of this thesis is to create a synthetic dataset through an automated process based on the work presented by \citet{patelLearningInterpretableStyle2023}. This dataset will contain group-specific explanations, each annotated with corresponding style and knowledge attributes.

      \item[Selecting the Dimensions of the Interpretable Attribute Vector]\hspace{\maxstretch}
            The synthetic dataset contains numerous style- and knowledge-related attributes. However, the interpretable attribute vector is limited to \num{\styleVectorSize} dimensions. Thus, the goal is to design an automatic selection process that identifies the most informative and relevant dimensions from the available attributes. This process builds upon the dimensionality selection strategy proposed by \citet{patelLearningInterpretableStyle2023}, providing a more targeted and efficient representation of group-specific characteristics.

      \item[Training of a Model that Produces the Interpretable Attribute Vector]
            With the selected attributes in place, the next goal is to train a model that can map any given text to an interpretable attribute vector. Each dimension of this vector corresponds to a specific style or knowledge attribute, with values ranging between \num{0} and \num{1}, indicating the extent to which the text exhibits each characteristic. The model is based on the architecture proposed by \citet{patelLearningInterpretableStyle2023}, which has been extended to incorporate both stylistic and knowledge-based components.

      \item[Creation of an Interpretable Attribute Embedding]\hphantom{at}
            Although the interpretable attribute vector is structured, its dimensions are not normalized. This limits the ability to directly compare different vectors. To address this issue, the model from the previous step is extended with an embedding head based on the approach presented by \citet{patelLearningInterpretableStyle2023}. This component generates normalized embeddings from the interpretable vectors that are suitable for group membership detection. These embeddings enable meaningful comparisons across texts and allow for clustering or classification of texts by group identity.

      \item[Steering a Large Language Model with System Prompt Engineering]\hspace{\maxstretch}
            This goal addresses research question~\ref{rq:generateExplanation:attributeVector} and explores how the interpretable attribute vector can improve system prompt engineering techniques for \acp{llm}. Different prompt construction strategies are designed and evaluated, with a focus on integrating the most relevant attribute dimensions for a target group. The goal is to generate outputs that align with the linguistic style and background knowledge of the target group by embedding these attributes into the system prompt.

      \item[Steering a Large Language Model with Activation Steering]\hphantom{i}
            The final goal of the thesis addresses research question~\ref{rq:generateExplanation:activation} and proposes a novel method for activation-based steering. This method manipulates the activations at the end of each transformer layer of the \ac{llm} by injecting steering vectors that are derived from internal model activations. The steering vectors are produced by combining activation vectors corresponding to specific dimensions of the interpretable attribute vector. Furthermore, this steering method is used in conjunction with various prompt steering methods to directly compare their performance.
\end{description}

Together, these goals form a comprehensive framework for interpretable text representation and personalized language model behavior. Beginning with the creation of the synthetic dataset, the thesis develops tools for generating and leveraging interpretable style and knowledge vectors. Ultimately, these tools are applied to guide the LLMs in ways that reflect group identity and communicative needs.

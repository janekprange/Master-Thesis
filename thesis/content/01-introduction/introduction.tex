\chapter{Introduction}
\label{sec:introduction}
% TODO: introduce interpretable attribute vector (dimensions, values between 0 and 1)
Textual information is an essential part of our daily lives, whether in educational settings, the news, entertainment, or social media. An important aspect of text is not only its content, but also the style in which it is written (\cite{wegmannSameAuthorJust2022}). Style dictates how the text is perceived and how well the reader understands and accepts the message. Additionally, stylistic features can be used to determine the author (\cite{alshomaryLatentSpaceInterpretation2024}) or group of people (\cite{10.1007/978-3-642-29047-3_27}) who wrote a text by comparing them between documents.

% TODO: reference figure
\begin{figure}[ht]
  \begin{center}
    \input{content/01-introduction/attribute-vector-tikz.tex}
    \caption{An example of a \num{\styleVectorSize}-dimensional attribute vector that was generated with the method presented in this thesis.} % TODO: more caption?
  \end{center}
\end{figure}

Previous work by \citet{zhu-etal-2024-styleflow, ijcai2020p526,wegmannSameAuthorJust2022} has recognized and researched the importance of style. However, there is a problem with automatic stylistic investigations. Manually annotating style, particularly creating parallel data with positive and negative examples for each label or style, is complicated and time-consuming. Since this is necessary for most supervised learning approaches, state-of-the-art style representation methods use unsupervised learning techniques that generate non-interpretable style embeddings. This makes it more difficult to verify the quality of the style representation and apply it to subsequent tasks.

% TODO: write better; do not mention text generation before it is introduced

State-of-the-art methods mainly use stylistic features for their tasks (\cite{alshomaryLatentSpaceInterpretation2024,patelLearningInterpretableStyle2023,konenStyleVectorsSteering2024,zhu-etal-2024-styleflow}). However, there are other aspects of the author, aside from style, that can be extracted to assist these methods, especially in generating group-specific explanations. This includes information about the author's background knowledge or experience, subsequently called knowledge attributes.

While producing style representations is useful, one of the currently most important tasks in natural language processing is generating text. \Acp{llm} are a popular tool for generating natural language, made possible by transformer architecture (\cite{NIPS2017_3f5ee243}). In recent years, they have been used for various tasks by a wide range of audiences, including the explanation of many topics and concepts. However, due to the large number of people using \acp{llm}, new problems arise. While it is important that the explanations are factually correct, it is also necessary to consider the audience's linguistic style and background knowledge and adapt the text generation accordingly. For instance, a technical explanation intended for a Ph.D. student would likely be unhelpful for a middle schooler, and vice versa. Style representations play a potentially important role here, in addition to their use in authorship attribution and group membership detection.


% TODO: include question 1.1? I could show experiments how important knowledge attributes are to differentiate groups
\section{Problem Statement}
\label{sec:introduction:problemStatement}

Previous research has demonstrated that existing methods are highly effective for authorship attribution tasks. These approaches identify and distinguish individual writing styles, enabling the attribution of anonymous texts to specific authors with a high degree of accuracy. However, the goal of this thesis is to adapt and extend these techniques to address a related yet distinct challenge: group membership detection.

Though similar in concept, group membership detection differs from authorship attribution in significant ways. Like authorship attribution, group membership detection relies on distinguishing characteristics in the way texts are written. Groups often exhibit unique stylistic features that can serve as indicators of group identity. However, the underlying data structure presents a key distinction. Authorship attribution typically involves many authors, each of whom contributes a small number of texts. In contrast, group membership detection usually involves only a few groups, each of which provides a relatively large volume of textual data. This fundamental difference in data composition requires new approaches tailored specifically to group detection.

\begin{description}
  \item[Research Question 1] How well are the interpretable style representations suited to detect the group membership of different authors?
\end{description}

To investigate this question, this thesis extends the interpretable style representation model proposed by \citet{patelLearningInterpretableStyle2023}. The extension involves augmenting the existing style vector with additional knowledge-based attributes. These attributes capture essential information such as the experience level and background knowledge of the authors, which are factors that can vary significantly between groups. As these knowledge characteristics influence the manner in which individuals express ideas in writing, their inclusion has the potential to enhance the model's ability to differentiate between groups.

\begin{description}
  \item[Research Question 1.1] Does the interpretable style representation benefit from knowledge attributes in addition to style attributes?
\end{description}

While the task of detecting group membership is valuable in itself, as \aclp{llm} are becoming more popular, the ability to use them to generate group-specific explanations has gained increasing relevance. \acp{llm} are used in many applications to explain concepts to large variety of groups of people. While the factual correctness of these explanations is important, the comprehensibility of the explanation is increased if the model can reflect the style and background knowledge of the recipient of the explanation. This thesis compares different steering methods and how the interpretable attribute vector that is presented in the first part of the thesis can contribute to existing methods for steering \ac{llm} outputs to better align with group-specific characteristics.

\begin{description}
  \item[Research Question 2] What is the best way to generate group-specific explanations from style representations?
\end{description}

To address this question, several steering methods for \acp{llm} will be examined. The initial focus will be on system prompt engineering, a widely used and accessible method for influencing model behavior. In particular, the thesis explores how the interpretable attribute vector can be used to guide the construction of system prompts that produce group-specific outputs. This includes formulating prompts to include dimensions of the interpretable attribute vector that are particularly relevant to a specific group.

\begin{description}
  \item[Research Question 2.1] Can the attribute vector presented in this thesis be used to improve existing steering methods that change the system prompt?
\end{description}

Despite its popularity, steering through system prompt modification has the limitation that it does not allow for fine-grained control over the steering. While it can guide the model in a general direction, it lacks the capacity to precisely modulate the strength of the steering effect.

To overcome this limitation, this thesis introduces a novel method for fine-grained steering that manipulates the activation space of the \ac{llm}. This technique involves altering the model's internal representations after specific layers, steering the activations toward particular conceptual directions that correspond to the dimensions of the interpretable attribute vector. This method builds upon recent research in activation-based model manipulation, including the work of \citet{konenStyleVectorsSteering2024,turnerActivationAdditionSteering2024,rimsky-etal-2024-steering}.

\begin{description}
  \item[Research Question 2.2] Can the newly proposed method of steering a \ac{llm} by manipulating its activation space be used to improve existing steering methods?
\end{description}


\section{Goals of the thesis}
\label{sec:introduction:goals}
\newlength{\maxstretch}
\setlength{\maxstretch}{0pt plus 1fill}
This thesis is guided by the research questions defined in Section~\ref{sec:introduction:problemStatement} and describes a continuous process. This process begins with preparing input data and ends with generating group-specific outputs from a steered model. Each goal contributes to the development of a framework for identifying group membership and steering language model behavior accordingly.

\begin{description}
  \item[Automatic Creation of an Annotated Synthetic Dataset]
        Annotating a large text corpus with diverse style and knowledge attributes is a difficult and time-consuming task. This challenge is amplified by the need for diverse attributes that are not bound to predefined topics. To address this issue, the first goal of this thesis is to create a synthetic dataset through an automated process based on the work presented by \citet{patelLearningInterpretableStyle2023}. This dataset will contain group-specific explanations, each annotated with corresponding style and knowledge attributes.

  \item[Selecting the Dimensions of the Interpretable Attribute Vector]\hspace{\maxstretch}
        The synthetic dataset contains numerous style- and knowledge-related attributes. However, the interpretable attribute vector is limited to \num{\styleVectorSize} dimensions. Thus, the goal is to design an automatic selection process that identifies the most informative and relevant dimensions from the available attributes. This process builds upon the dimensionality selection strategy proposed by \citet{patelLearningInterpretableStyle2023}, providing a more targeted and efficient representation of group-specific characteristics.

  \item[Training of a Model that Produces the Interpretable Attribute Vector]
        With the selected attributes in place, the next goal is to train a model that can map any given text to an interpretable attribute vector. Each dimension of this vector corresponds to a specific style or knowledge attribute, with values ranging between \num{0} and \num{1}, indicating the extent to which the text exhibits each characteristic. The model is based on the architecture proposed by \citet{patelLearningInterpretableStyle2023}, which has been extended to incorporate both stylistic and knowledge-based components.

  \item[Creation of an Interpretable Attribute Embedding]\hphantom{at}
        Although the interpretable attribute vector is structured, its dimensions are not normalized. This limits the ability to directly compare different vectors. To address this issue, the model from the previous step is extended with an embedding head based on the approach presented by \citet{patelLearningInterpretableStyle2023}. This component generates normalized embeddings from the interpretable vectors that are suitable for group membership detection. These embeddings enable meaningful comparisons across texts and allow for clustering or classification of texts by group identity.

  \item[Steering a Large Language Model with System Prompt Engineering]\hspace{\maxstretch}
        This goal addresses research question 2.1 and explores how the interpretable attribute vector can improve system prompt engineering techniques for \acp{llm}. Different prompt construction strategies are designed and evaluated, with a focus on integrating the most relevant attribute dimensions for a target group. The goal is to generate outputs that align with the linguistic style and background knowledge of the target group by embedding these attributes into the system prompt.

  \item[Steering a Large Language Model with Activation Steering]\hphantom{i}
        The final goal of the thesis addresses research question 2.2 and proposes a novel method for activation-based steering. This method manipulates the activations at the end of each transformer layer of the \ac{llm} by injecting steering vectors that are derived from internal model activations. The steering vectors are produced by combining activation vectors corresponding to specific dimensions of the interpretable attribute vector. Furthermore, this steering method is used in conjunction with various prompt steering methods to directly compare their performance.
\end{description}

Together, these goals form a comprehensive framework for interpretable text representation and personalized language model behavior. Beginning with the creation of the synthetic dataset, the thesis develops tools for generating and leveraging interpretable style and knowledge vectors. Ultimately, these tools are applied to guide the LLMs in ways that reflect group identity and communicative needs.

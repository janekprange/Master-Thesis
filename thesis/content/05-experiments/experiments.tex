\chapter{Experiments and Evaluation}
\label{sec:experiments_evaluation}


\section{Environment and Hardware}
\label{sec:experiments_evaluation:environmentHardware}

\begin{itemize}
  \item node on a SLURM server cluster
        \begin{itemize}
          \item 32 CPU Cores % or 32?
          \item \SI{128}{\giga\byte} RAM % or 128?
          \item Nvidia A-100 GPU with \SI{40}{\giga\byte} RAM
        \end{itemize}
  \item Python Version
  \item sqlite Database as data storage? â†’ show schema diagram in appendix
\end{itemize}


\section{Architecture and Models used}
\label{sec:approach:architectureModels}

\subsection{Architecture}
\label{sec:approach:architectureModels:architecture}

\begin{itemize}
  \item Attribute Sentence Generation
  \item Clustering
  \item Selection of Attribute Vector dimensions
  \item Training SFAM and LISA
  \item Training the embedding model
  \item Prompt Steering
  \item Activation Steering
\end{itemize}

\subsection{Models}
\label{sec:approach:architectureModels:models}

\begin{itemize}
  \item Llama3.2
  \item Sentence Transformer
  \item DeBERTaV3
  \item \ldots
\end{itemize}

\section{Implementation}

\subsection{Creation of the Synthetic Dataset}
\begin{itemize}
  \item to embed the attribute sentences, the model \textit{all-MiniLM-L12-v2} (\cite{reimersSentenceBERTSentenceEmbeddings2019}) has been used
  \item for clustering, sentences must have a cosine similarity of \num{\minCosineSimilarity} or less to be in the same cluster
  \item resulting dataset in Table~\ref{table:syntheticDataset}
\end{itemize}
\begin{table}[ht]
  \begin{center}
    % TODO: alignment of numbers inside the \num command
    \begin{tabular}{lS[table-format=7.0]}
      \toprule
                   & {Number of data points} \\ \midrule
      Answers      & \numAnswersStyleVector  \\
      Prompts      & \numPrompts             \\
      Descriptions & \numStyleDescriptions   \\
      Sentences    & \numStyleSentences      \\
      Clusters     & \numClusters            \\ \bottomrule
    \end{tabular}
    \caption{The number of answers and prompts used to create the synthetic dataset and the size of the resulting dataset.}
    \label{table:syntheticDataset}
  \end{center}
\end{table}

\subsection{Attribute Selection}
\begin{itemize}
  \item \num{\numClusters} clusters
  \item \num{\numAnswersStyleVector} answers by \num{\numGroups} groups
  \item select only \num{\styleVectorSize} attributes for the interpretable attribute vector
  \item filtering out too frequent
        \begin{itemize}
          \item max \clusterMaxGroupRatio{} of groups (number taken from \citet{patelLearningInterpretableStyle2023})
          \item number of clusters smaller er than \num{\maxClustersFirstSelection}. This number was chosen to be small enough for the following computation but big enough to enable a meaningful selection of attribute vector dimensions.
        \end{itemize}
  \item too similar
        \begin{itemize}
          \item \num{\maxCosineSimilarity} maximum cosine similarity
          \item In the work of \citeauthor{patelLearningInterpretableStyle2023}, they use a maximum cosine similarity of \num{0.8} as a cutoff. I decided to use a lower maximum similarity to increase the variance of the attribute vector dimensions and because of the clusters. % TODO: better explanation
        \end{itemize}
\end{itemize}


\section{Evaluation Metrics}
\label{sec:approach:evaluationMetrics}

\begin{itemize}
  \item SFAM
        \begin{itemize}
          \item accuracy and F1 with regard to labels from select examples of the attribute sentence generation (was the sentence used or not)
        \end{itemize}
  \item LISA
        \begin{itemize}
          \item MSE, MAE, avg. cosine similarity compared to SFAM prediction
          \item accuracy and F1 compared to SFAM where both predictions are rounded
        \end{itemize}
  \item embedding model
        \begin{itemize}
          \item accuracy through triplet loss
                %? \item variance inside groups
        \end{itemize}
  \item steering methods
        \begin{itemize}
          \item improvement of L2 distance to group median compared to embedding of unsteered generation
                \begin{itemize}
                  \item how strong is the steering?
                \end{itemize}
          \item cosine similarity between the vector that is the difference between embedding of steered and unsteered generation
                \begin{itemize}
                  \item is the steering in the correct direction?
                \end{itemize}
                %? \item the absolute times that the resulting group is the correct one (according to the embedding)
        \end{itemize}
\end{itemize}


\begin{figure}
  \begin{center}
    \input{content/05-experiments/steering-metrics-plot.tex}
    \captionsetup{singlelinecheck=off}
    \caption[]{%
      All answers that are generated during steering are embedded using the \ac{lisa} model with the embedding head. For each question, the \ac{llm} is prompted without any steering to create an unsteered baseline. Then, for each group and each steering type, the model is prompted with the same question. The median group embedding is derived from the embeddings of all answers that have been used to train \ac{sfam} and \ac{lisa}.
      The quality of each steering method is measured with different metrics:
      \begin{enumerate*}
        \item \textbf{Steering Direction Correctness:} The cosine similarity between the steering effect vector and the optimal steering effect vector.
        \item \textbf{Steering Effect:} The euclidean distance of the steering effect vector.
        \item \textbf{Optimal Steering Effect:} The euclidean distace between the unsteered embedding and the median group embedding.
        \item \textbf{Possible Improvement:} The euclidean distance between the steered embedding and the median group embedding.
              % \item difference between steering effect and optimal steering effect
              % \item difference (or ratio?) between steering effect and possible steering effect
      \end{enumerate*}
    }
  \end{center}
\end{figure}

\section{Steering}
\label{sec:experiments_evaluation:steering}

\begin{itemize}
  \item questions taken from \citet{petroni-etal-2021-kilt,rooeinKnowYourAudience2023}
\end{itemize}
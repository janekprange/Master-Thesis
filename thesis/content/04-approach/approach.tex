% !TeX root = ..\..\thesis.tex
\chapter{Approach}
\label{sec:approach}

\section{Possible Improvement through Knowledge Attributes}
\label{sec:approach:knowledgeAttributes}
Where can I put this?


\section{Attribute Sentence Generation}
\label{sec:approach:attributeSentenceGeneration}

The attribute sentences that form the dimensions of the interpretable attribute vector are generated by prompting a \acl{llm} in a two-step procedure.

For step one, the \ac{llm} is presented with a zero-shot prompt to produce a description of the text. This step is repeated \num{\numPrompts} times, each time with a different prompt that focuses on a specific aspect of the text. \num{\numOpenPrompts} prompts are relatively open and only give a loose direction on which style should be described by the model. \num{\numTargetPrompts} prompts (see Appendix~\ref{sec:appendix:targetAttributes}) are targeted towards an explicit stylistic feature. These prompts follow the work of \citet{patelLearningInterpretableStyle2023,tausczikPsychologicalMeaningWords2010} to get the model to focus on a broad variety of style that is important for the study of language.

In addition to these prompts aimed at stylistic features, there are \num{\numKnowledgePrompts} prompts which are focusing on the knowledge and experience of the author. While the background knowledge of the author is not as important for the group membership detection as the style of the text, it is helpful information for the steering task that is covered in later sections.

After generating the descriptions, the \ac{llm} is prompted a second time to rewrite them as a list of sentences. The model is instructed to write each sentence in a consistent form like \enquote{The author is \ldots} or \enquote{The author uses \ldots}.

Furthermore, the model is instructed to avoid negations and examples since these both lead to increasing problems with the clustering process that is described in Section~\ref{sec:approach:clustering}.
Sentences that include examples are potentially problematic because it increases the likelihood of sentences which have the exact same content while being of different shape. % TODO: better wording
Two sentences which differ only in the example are \enquote{The author uses filler words} and \enquote{The author uses filler words such as 'and', 'or' and 'furthermore'}. While this problem will be reduced by clustering similar sentences, this procedure is not perfect and will be more robust if the model avoids sentences with examples.

Negations on the other hand lead to the problem where the shape of the sentences will be too close while the content is very different. There is a high chance that the sentences \enquote{The author does use long sentences} and \enquote{The author does not use long sentences} will be clustered together because so much of them is the same even though they state the opposite of each other.
Additionally, the dimensions of the final attribute vector should not include any negated attributes since the expression \enquote{The author uses short sentences} is much clearer than \enquote{The author does not use long sentences}.

Since the model might produce sentences with negations or examples despite the prompt, each of the generated sentences is checked automatically.

Per description, each distinct attribute sentence is recorded only once, even if the model generates it multiple times. This is done in case the model generates a bad answer where one sentence is repeated many times.

The whole process can be seen in Figure~\ref{fig:attributeSentenceGeneration}.

\begin{figure}[ht]
  \input{content/04-approach/sentence-generation-diagram.tex}
  % TODO: better caption
  \caption{The process to generate attribute sentences.}
  \label{fig:attributeSentenceGeneration}
\end{figure}


\section{Clustering}
\label{sec:approach:clustering}
A strength of the method to create attribute sentences described in Section~\ref{sec:approach:attributeSentenceGeneration} is the lack of constraints which results in a large variety of generated sentences. However, this leads to the problem that sentences with the same content can have many different forms. An example for this would be the sentences \enquote{The author uses short and concise sentences.} and \enquote{The author uses concise and short sentences.}, which have exactly the same meaning while having a distinct form.

Since the approach up to this point only checked if sentences are exactly identical, it is more difficult to compare different input texts and to find texts that are an example of a specific attribute sentence. Additionally, it could be that a sentence would be a good dimension for the attribute vector but is not selected by the algorithm described in Section~\ref{sec:approach:selection} because it is used with too many different variations.
To solve this problem, my approach includes clustering the sentences by the cosine similarity of their embeddings which are produced by a sentence embedding model. % TODO: citation for the model (and name?)

The clustering algorithm first computes a radius neighbor graph of all sentences where sentences which have a cosine similarity of more than \num{\minCosineSimilarity}. Subsequently, the clusters are sorted by size and all sentences that have been included in a larger cluster are deleted from all smaller clusters to ensure that each sentence is only included in one cluster. At the same time, it has to be ensured that no sentence is left out of every cluster because for further approaches, the clusters are the relevant data.

For the resulting clusters, the attribute sentence that is closest to the center is the representative sentence of the whole cluster.

The size of the resulting synthetic dataset after clustering can be found in table~\ref{table:syntheticDataset}.

\begin{table}
  \begin{center}
    % TODO: alignment of numbers inside the \num command
    \begin{tabular}{lS}
      \toprule
                   & {Number of data points} \\ \midrule
      Answers      & \numAnswersStyleVector  \\
      Prompts      & \numPrompts             \\
      Descriptions & \numStyleDescriptions   \\
      Sentences    & \numStyleSentences      \\
      Clusters     & \numClusters            \\ \bottomrule
    \end{tabular}
    \caption{The number of answers and prompts used to create the synthetic dataset and the size of the resulting dataset.}
    \label{table:syntheticDataset}
  \end{center}
\end{table}


% \begin{itemize}
%   \item often, style sentences are generated that are very similar
%   \item e.g. \enquote{The author uses short and concise sentences.} and \enquote{The author uses concise and short sentences.}
%   \item If one style sentence is used very often but in many different variations, it may not get selected for the style sentence vector because each variation by itself has not occured often enough
%   \item The sentences are embedded with the model x % TODO: write that here?
%   \item because of that, all style sentences are clustered so that sentences which embeddings have a cosine distance of less than 0.15 count as the same sentence. The sentence that is closest to the center functions as the representation of the whole cluster
%   \item each sentence can only be in one cluster; if it is in multiple clusters it is removed from all but the largest
%   \item each sentence has to be in exactly one clusters, so many clusters include only one sentence
% \end{itemize}


\section{Selecting the Attribute Vector Dimensions}
\label{sec:approach:selection}

Following the previous steps, there is now a synthetic dataset with \num{\numClusters} that describe \num{\numAnswersStyleVector} answers by \num{\numGroups}. Since the final attribute vector will only consist of \num{\styleVectorSize} dimensions, a process to select the best ones is needed. This selection is carried out in multiple steps.

\subsection{Selection of target attributes}
\label{sec:approach:selection:targetAttributes}
Following the work of \citet{patelLearningInterpretableStyle2023}, the first \num{\numTargetPrompts} attributes of the attribute vector will be selected to correspond to the \num{\numTargetPrompts} target prompts which were described in section~\ref{sec:approach:attributeSentenceGeneration}.
This is done to ensure that the attribute vector has a robust foundation on some features that are manually selected for being relevant for stylistic research. The ability to automatically create most of the attribute vector is not significantly reduced since the target attributes only account for around \SI{10}{\percent} of its size.

These attributes are found by creating sentences of the form \enquote{The author uses <target>} and embedding using a SentenceTransformer model. % TODO: correct name
Afterward, for each sentence the style cluster with the highest cosine similarity is found. The knowledge clusters are not taken into account during this selection.
All clusters that have been chosen this way to represent the
% TODO: find a nice final sentence


\subsection{Filtering out attributes that occur too frequently}
\label{sec:approach:selection:filteringOccurance}
An important characteristic of all attributes that are part of the attribute vector is that they are as meaningful as possible and helpful to distinguish different groups. Because of that, this step in the cluster selection ensures that only clusters which are used to describe texts by less than \clusterMaxGroupRatio{} of the groups are selected. The cutoff ratio of groups follows the work of \citet{patelLearningInterpretableStyle2023}.

For the next steps of the cluster selection, it is also important that there are not too many possible clusters to select from, otherwise the computation would need too much time and memory. To quickly reduce the number of clusters, the number of times the cluster was used to describe answers is taken into account. The required number of times used is increased until the resulting number of clusters is smaller than \num{\maxClustersFirstSelection}. This number was chosen to be small enough for the following computation but big enough to enable a meaningful selection of attribute vector dimensions.

% TODO: include this?
A cluster could be used multiple times to describe the same answer. Although the sentence produced by each prompt is only counted once per prompt, multiple prompts could use the same or similar enough sentences to describe the answer. For this selection however, only the number of answers that have been described with the cluster are being counted and not how often the cluster was being used.

\subsection{Removing too similar Attributes}
\label{sec:approach:selection:removeSimilar}
To ensure that the attribute vector covers a wide range of attributes, it is important that the attributes do not cover too similar topics. This selection step fulfills this requirement by making sure that the attribute vector dimensions have a maximum cosine similarity of \num{\maxCosineSimilarity}. This process works by ordering the clusters by occurrence, selecting them one after the other and deleting all clusters that are too close to the ones that have already been selected.

In the work of \citeauthor{patelLearningInterpretableStyle2023}, they use a maximum cosine similarity of \num{0.8} as a cutoff. I decided to use a lower maximum similarity to increase the variance of the attribute vector dimensions and because of the clusters. % TODO: better explanation

\subsection{Final Selection} % TODO: better name?
\label{sec:approach:selection:finalSelection}
The first \num{\numTargetPrompts} dimensions of the attribute vector are the target attributes that were selection in Section~\ref{sec:approach:selection:targetAttributes}. The next \num{\minNumKnowledgePrompts} dimensions are knowledge clusters, that is clusters of sentences that were produced by knowledge prompts. The rest of the dimensions are selected in this step to be the ones with the highest range of accordance. % TODO: better word than accordance?

Range of accordance means that the range between the answers that match the attribute really well and the ones that do not match is as big as possible. This further increases the probability that the attributes are well suited to distinguish between different answers and groups.

First, the similarity between all clusters that remain after the first selection steps are computed. Afterward, the for each cluster and each answer the average similarity to all other clusters that have been used to describe that answer is computed. TODO:


% \begin{itemize}
%   \item \minNumKnowledgePrompts{} knowledge clusters are selected
%   \item compute similarities between clusters selected at this stage
%   \item for all clusters, compute the average similarity of all input texts by looking at the clusters that have been used to describe that input text
%   \item sort the clusters by the difference between the most and least matching input text
%   \item select the clusters with the highest difference
%   \item this is done because a style attribute will probably hold more meaningful information and is better suited to differentiate texts if it is very similar to some and very dissimilar to other texts
% \end{itemize}


\section{Training and Testing \acs{sfam}}
\label{sec:approach:sfam}

The goal of the method presented in this thesis is to create interpretable attribute vectors with values between \num{0} and \num{1} that correspond to real world values. To create these values, I will train a model that follows the \acf{sfam} that was presented by \citet{patelLearningInterpretableStyle2023}. It takes an attribute sentence and a text and outputs and agreement score that corresponds to how well the attribute sentence fits to the text.

\ac{sfam} is trained on the synthetic dataset which was created in earlier steps as described in Section~\ref{sec:approach:attributeSentenceGeneration}. The training data includes the unclustered knowledge and style sentences and the input texts that were described by them. There is however some preprocessing necessary, because just because an attribute sentence was not used to describe a text does not mean the text does not match the sentence. It could be that the text was described by a similar sentence or that the \ac{llm} just skipped a topic when describing one text.

The attribute sentences that are used for training are selected in a process similar to the one described in Section~\ref{sec:approach:selection:finalSelection}.
First, the similarity between all attribute sentences and all Attribute Vector dimensions are computed. Then, for each sentence and each text the average similarity to the dimensions that were used to describe the text is computed. The texts are then sorted by their similarity to the attribute sentence. If the sentence has been used to describe one of the \SI{1}{\percent} most similar texts, this text will be used as a positive training sample and the most dissimilar text where the sentence was not used to describe it is used as a negative training sample. Otherwise, the sentence will not be used for training.

The result dataset is balanced regarding positive and negative samples and has a high probability to only include sentences which actually fit the texts. % TODO: write better
The same process is used to create the validation and test dataset using different answers. % TODO: write here that the attribute sentences are largely distinct or later in experiments?

% \begin{itemize}
%   \item \ac{sfam} is a model that takes a style sentence and a text as input and produces an agreement score
%   \item training data
%         \begin{itemize}
%           % \item the \numStyleSentences{} style sentences are used for training % do not use numbers for approach
%           \item there are distinct sets of input texts for training, validation and test datasets
%           \item these lead to mostly different sentences (also the differences may be small)
%           \item of all sentences, the best are selected
%                 \begin{itemize}
%                   \item compute similarity to all style vector attributes (which are clusters)
%                   \item for each sentence, compute the most similar and most dissimilar input text according to the average similarity to all style attributes that have been used to describe that text (like the final selection of style vector attributes, see Section~\ref{sec:approach:selection}) % TODO: is there a more specific reference to a subsection?
%                   \item if one of the ten most similar input texts was actually described by the style sentence, it is chosen as a positive training sample and the least similar input text that was not described by the sentence as a negative sample
%                   \item otherwise, the sentence is not used for training
%                   \item the same is done for validation and test
%                 \end{itemize}
%         \end{itemize}
%   \item \ac{sfam} is a finetuned DeBERTaV3 model
%         \begin{itemize}
%           \item two fully connected layers with a ReLu in between % TODO: look up
%           \item finally a sigmoid activation function to produce values between 0 and 1
%         \end{itemize}
%   \item optional hyperparameter optimization (with optuna -> citation?) to discover optimal learning rate and weight decay
%   \item early stopping callback with patience of three
%   \item validation metric of accuracy
%   \item testing metric accuracy and f1
% \end{itemize}


\section{Training and Testing \acs{lisa}}
\label{sec:approach:lisa}
While \ac{sfam} produces the Attribute Vector with exactly the values that are required, it needs on forward pass per dimension of the vector. Even with an optimized model this takes a too long time for the most applications. The solution is to train an additional model which for the \acf{lisa} model proposed by \citet{patelLearningInterpretableStyle2023}, which gets a text as an input and produces the full Attribute Vector in one forward pass.

The training, validation and test data is created by using \ac{sfam} to create the Attribute Vectors of the corresponding texts and training \ac{lisa} as a regression model.

% \begin{itemize}
%   \item to get values for a style vector, the \num{\styleVectorSize} forward passes by \ac{sfam} would take too long for most practical applications
%   \item train an additional model that creates the whole vector in one forward pass
%   \item \ac{lisa} like \ac{sfam} is a finetuned DeBERTaV3 model
%         \begin{itemize}
%           \item two fully connected layers with a ReLu in between % TODO: look up
%           \item finally a sigmoid activation function to produce values between 0 and 1
%         \end{itemize}
% \end{itemize}

\section{Embedding Model}
\label{sec:approach:embedding}
The \ac{lisa} model produces an attribute vector where each dimension corresponds to one attribute sentence. The problem with this vector is that two vectors can not be easily compared to each other because the dimensions are not normalized and have different importances for the meaning of the vector.

Because of that, I train an embedding head for the \ac{lisa} model that produces attribute embeddings. While the dimensions of the embedding are not directly interpretable, they are derived directly from the interpretable attribute vectors and therefore do not lose much interpretability.

\section{Steering Text Generation}
In this thesis, I aim to combine the group membership task with the steering of \acp{llm} towards group specific explanations. Multiple different methods will be presented and compared to each other. The method split into to groups; changing the system prompt to steer the model and manipulating the output of the activation functions after selected layers.

\subsection{Prompt Steering}
\label{sec:approach:steering:prompt}
I will be looking at three different methods of changing the system prompt to adapt the way the \ac{llm} answers questions by the user to match a specific group.

The first and simplest way is to change the system prompt is to instruct the model to write for an explanation for a group. In this case, the system prompt includes the following sentence:
\begin{quote}
  You are an author that writes a helpful explanation for a group of <group>.
\end{quote}

While this method can not be influenced regarding the direction or strength of the steering effect, it is very easy to implement and will serve as a baseline to compare the other steering methods against.

For the second prompt steering approach, the data that is used to extract the features of the attribute vector as described in Section~\ref{sec:approach:attributeSentenceGeneration} will be used to determine the most important attributes that differentiate each group from all the others. The most important style and knowledge attribute will then be a part of the system prompt.

For the attributes to be able to be effectively used in the system prompt, they can not be of the form \enquote{The author is \ldots}. Instead, the attributes are automatically rewritten to address the model directly as this role playing is a strength of modern \aclp{llm}. % TODO: citation
Thus, the attribute sentences will have the form \enquote{You are \ldots}.

The final prompt steering methods will combine the two previous methods and include both the group name and the most important attribute sentences in the system prompt.

\section{Activation Steering}
\label{sec:approach:steering:activation}
\begin{itemize}
  \item strength of the method is that no training is needed
  \item the activation vectors will be extracted at each layer
  \item for each attribute vector dimension, an activation vector is extracted
  \item to create the steering vector for the layer x
        \begin{enumerate}
          \item take the attribute vector (for example for a group)
          \item take a softmax
          \item multiply the activation vector of each attribute sentence with the corresponding softmax value
          \item add the weighted activation vectors together
          \item multiply them with a factor \(\lambda\)
        \end{enumerate}
  \item the steering vector is added to the activation vector at layer x during the forward pass of a steered text generation
\end{itemize}

\subsubsection{Extracting Steering Vectors}

\subsubsection{Text Generation Steering}
% !TeX root = ..\..\thesis.tex
\chapter{Approach}
\label{sec:approach}

This thesis proposes a method to create an interpretable attribute vector which will be used for group membership detection. An attribute vector is similar to style vector introduced in previous works (\cite{konenStyleVectorsSteering2024,wegmannSameAuthorJust2022,patelLearningInterpretableStyle2023,alshomaryLatentSpaceInterpretation2024}). In contrast to the style vector, which focuses on stylistic features of text, the attribute vector will also include knowledge attributes. These capture the background knowledge and experience of the author.
The dimensions of the attribute vector are values between \num{0} and \num{1} where each dimension corresponds to an attribute sentence with a real world meaning.

In addition to the attribute vector, this thesis presents different methods to steer the output of \acp{llm}, which will be used to create group-specific explanations for various topics. The interpretable attribute vector will be used for both the steering process and its evaluation. For this task, the knowledge attributes of the attribute vector will be especially helpful.

% TODO: explain why the knowledge attributes are important

% Previous work by \citet{patelLearningInterpretableStyle2023,alshomaryLatentSpaceInterpretation2024} focus on stylistic attributes for authorship attribution tasks. In this thesis, I will extend the style vector by knowledge attributes, which focus on the experience and background knowledge of the author. While these attributes are not as important for authorship attribution or group membership detection tasks, they will be helpful to steer explanations towards the appropriate knowledge level for specific groups of people. The style and knowledge attributes together form the attribute vector.

\section{Attribute Sentence Generation}
\label{sec:approach:attributeSentenceGeneration}

The attribute sentences that form the dimensions of the interpretable attribute vector are generated by prompting a \acf{llm} in a two-step procedure building upon the work of \citet{patelLearningInterpretableStyle2023}.

For step one, the \ac{llm} is presented with a zero-shot prompt to produce a description of the input text. This step is repeated \num{\numPrompts} times, each time with a different prompt that focuses on a specific aspect of the text. \num{\numOpenPrompts} prompts (see Appendix~\ref{sec:appendix:openPrompts}) are relatively open and only give a loose direction on which style should be described by the model. \num{\numTargetPrompts} prompts (see Appendix~\ref{sec:appendix:targetPrompts}) are targeted towards an explicit stylistic feature. These prompts follow the work of \citet{patelLearningInterpretableStyle2023,tausczikPsychologicalMeaningWords2010} to get the model to focus on a broad variety of styles that are important for the study of language. These prompts are the basis for the style attributes of the attribute vector.

Extending the method presented by \cite{patelLearningInterpretableStyle2023}, there are \num{\numKnowledgePrompts} prompts (see Appendix~\ref{sec:appendix:knowledgePrompts}) which focus on the knowledge and experience of the author in addition to the style prompts. These prompts are the basis for the knowledge attributes.

After generating the descriptions, the \ac{llm} is prompted a second time to rewrite them as a list of sentences. The model is instructed to write each sentence in a consistent form like \enquote{The author is \ldots} or \enquote{The author uses \ldots}. This process is shown in Figure~\ref{fig:attributeSentenceGeneration}.

\begin{figure}[ht]
  \input{figures/tikz/sentence-generation-diagram.tex}
  % TODO: better caption
  \caption{The process to generate attribute sentences.}
  \label{fig:attributeSentenceGeneration}
\end{figure}

In addition to the requirement towards the shape of the sentences, the model is instructed to avoid negations and examples since these both lead to increasing problems with the clustering process that is described in Section~\ref{sec:approach:clustering}.
Sentences that include examples are potentially problematic because it increases the likelihood of sentences which have the same content while being of significantly different shape; an example for this problem would be the sentences \enquote{The author uses filler words} and \enquote{The author uses filler words such as 'and', 'or' and 'furthermore'}.% While this problem will be reduced by clustering similar sentences, the procedure is not perfect and will be more robust if the model avoids sentences with examples.

Negations, on the other hand, lead to the problem where the shape of the sentences will be too close while the content is very different. There is a high chance that the sentences \enquote{The author does use long sentences} and \enquote{The author does not use long sentences} will be regarded as very similar because so much of them is the same, even though they state the opposite content of each other.
Additionally, the dimensions of the final attribute vector should not include any negated attributes since the expression \enquote{The author uses short sentences} is much clearer than \enquote{The author does not use long sentences}.

Since the model might produce sentences with negations or examples despite the prompt, each of the generated sentences is also automatically checked before further processing, following the work of \citet{patelLearningInterpretableStyle2023}.

Per description, each distinct attribute sentence is recorded only once, even if the model generates it multiple times. This is done in case the model generates a bad answer where one sentence is repeated many times.


\section{Clustering}
\label{sec:approach:clustering}
A strength of the method to create attribute sentences described in Section~\ref{sec:approach:attributeSentenceGeneration} is the lack of constraints which results in a large variety of generated sentences. However, this leads to the problem that sentences with the same content can have many different shapes. An example for this would be the sentences \enquote{The author uses short and concise sentences.} and \enquote{The author uses concise and short sentences.}, which have the same meaning while being considered as two completely different sentences by the procedure up to this point.

Because of that, it is more difficult to compare different input texts and to find texts that fit a similar feature attribute.
% Additionally, the selection of the dimension of the attribute vector described in Section~\ref{sec:approach:selection} could become more difficult as the number of times that an attribute has been used is obscured. % maybe other wording, but probably don't reference future sections
To solve this problem, my approach extends the method presented by \citet{patelLearningInterpretableStyle2023} to cluster the sentences by the cosine similarity of their embeddings, which are produced by a sentence embedding model.
The sentence that is closest to the center of each cluster represents it. When the cluster is used, this sentence and its embedding are actually used.

This process is carried out separately for sentences that have been produced by style prompts and those produced by knowledge prompts (see Section~\ref{sec:approach:attributeSentenceGeneration}). This ensures that there is mixing between style and knowledge attributes.
% Otherwise, it could happen that a cluster includes lots of knowledge sentences, but the center sentence is a style sentence, which could cause some problems in the later stages of the approach.
The resulting clusters are referred to as style clusters and knowledge clusters.

% TODO: cluster selection?

\section{Training and Testing \acs{sfam}}
\label{sec:approach:sfam}

The goal of the method presented in this thesis is to create interpretable attribute vectors with values between \num{0} and \num{1} that correspond to real-world values. To create these values, a model will be trained which follows the \acf{sfam} that was presented by \citet{patelLearningInterpretableStyle2023}. It takes an attribute sentence and a text and outputs an agreement score that corresponds to how well the attribute sentence fits the text.

\ac{sfam} is trained on the synthetic dataset, which was created in earlier steps as described in Section~\ref{sec:approach:attributeSentenceGeneration}. The training data includes the unclustered knowledge and style sentences and the input texts that were described by them. There is however some preprocessing necessary, because just because an attribute sentence was not used to describe a text does not mean the text does not match the sentence. It could be that the text was described by a similar sentence or that the \ac{llm} just skipped a topic when describing one text.

The attribute sentences that are used for training are selected in a process similar to the one described in Section~\ref{sec:approach:selection:finalSelection}.
First, the similarity between all attribute sentences and all attribute vector dimensions is computed. Then, for each sentence and each text, the average similarity to the dimensions that were used to describe the text is computed. The texts are then sorted by their similarity to the attribute sentence. If the sentence has been used to describe one of the \SI{1}{\percent} most similar texts, this text will be used as a positive training sample, and the most dissimilar text where the sentence was not used to describe it is used as a negative training sample. Otherwise, the sentence will not be used for training.

The resulting dataset is balanced regarding positive and negative samples and has a high probability of only including sentences that fit the texts. % TODO: write better
The same process is used to create the validation and test datasets using different answers. % TODO: write here that the attribute sentences are largely distinct or later in experiments?

% \begin{itemize}
%   \item \ac{sfam} is a model that takes a style sentence and a text as input and produces an agreement score
%   \item training data
%         \begin{itemize}
%           % \item the \numStyleSentences{} style sentences are used for training % do not use numbers for approach
%           \item there are distinct sets of input texts for training, validation and test datasets
%           \item these lead to mostly different sentences (also the differences may be small)
%           \item of all sentences, the best are selected
%                 \begin{itemize}
%                   \item compute similarity to all style vector attributes (which are clusters)
%                   \item for each sentence, compute the most similar and most dissimilar input text according to the average similarity to all style attributes that have been used to describe that text (like the final selection of style vector attributes, see Section~\ref{sec:approach:selection}) % TODO: is there a more specific reference to a subsection?
%                   \item if one of the ten most similar input texts was actually described by the style sentence, it is chosen as a positive training sample and the least similar input text that was not described by the sentence as a negative sample
%                   \item otherwise, the sentence is not used for training
%                   \item the same is done for validation and test
%                 \end{itemize}
%         \end{itemize}
%   \item \ac{sfam} is a finetuned DeBERTaV3 model
%         \begin{itemize}
%           \item two fully connected layers with a ReLu in between % TODO: look up
%           \item finally a sigmoid activation function to produce values between 0 and 1
%         \end{itemize}
%   \item optional hyperparameter optimization (with optuna -> citation?) to discover optimal learning rate and weight decay
%   \item early stopping callback with patience of three
%   \item validation metric of accuracy
%   \item testing metric accuracy and f1
% \end{itemize}


\section{Training and Testing \acs{lisa}}
\label{sec:approach:lisa}
While \ac{sfam} produces the Attribute Vector with exactly the values that are required, it needs one forward pass per dimension of the vector. Even with an optimized model, this takes too long a time for most applications. The solution is to train an additional model, the \acf{lisa} model proposed by \citet{patelLearningInterpretableStyle2023}, which gets a text as input and produces the full attribute vector in one forward pass.

The training, validation, and test data are created by using \ac{sfam} to create the Attribute Vectors of the corresponding texts and training \ac{lisa} as a regression model.

% \begin{itemize}
%   \item to get values for a style vector, the \num{\styleVectorSize} forward passes by \ac{sfam} would take too long for most practical applications
%   \item train an additional model that creates the whole vector in one forward pass
%   \item \ac{lisa} like \ac{sfam} is a finetuned DeBERTaV3 model
%         \begin{itemize}
%           \item two fully connected layers with a ReLu in between % TODO: look up
%           \item finally a sigmoid activation function to produce values between 0 and 1
%         \end{itemize}
% \end{itemize}

\section{Embedding Model}
\label{sec:approach:embedding}
The \ac{lisa} model produces an attribute vector where each dimension corresponds to one attribute sentence. The problem with this vector is that two vectors can not be easily compared to each other because the dimensions are not normalized and have different importance for the meaning of the vector.

Because of that, an embedding head for the \ac{lisa} model is trained that produces attribute embeddings. While the dimensions of the embedding are not directly interpretable, they are derived directly from the interpretable attribute vectors and therefore do not lose much interpretability.

\section{Steering Text Generation}
\label{sec:approach:steering}
% TODO: more introduction; why is steering important? talk about explanation generation
The aim of this thesis is to combine the group membership task with the steering of \acp{llm} towards group-specific explanations. Multiple different methods will be presented and compared to each other. The method is split into two groups: changing the system prompt to steer the model and manipulating the output of the activation functions after selected layers.

\subsection{Prompt Steering}
\label{sec:approach:steering:prompt}
I will be looking at three different methods of changing the system prompt to adapt the way the \ac{llm} answers questions by the user to match a specific group.

The first and simplest way to change the system prompt is to instruct the model to write an explanation for a specified group. In this case, the system prompt includes the following sentence:
\begin{quote}
  You are an author who writes a helpful explanation for a group of <group>.
\end{quote}

While this method can not be influenced regarding the direction or strength of the steering effect, it is very easy to implement and will serve as a baseline to compare the other steering methods against.

For the second prompt steering approach, the data that is used to extract the features of the attribute vector as described in Section~\ref{sec:approach:attributeSentenceGeneration} will be used to determine the most important attributes that differentiate each group from all the others. The most important style and knowledge attribute will then be a part of the system prompt.

For the attributes to be able to be effectively used in the system prompt, they can not be of the form \enquote{The author is \ldots}. Instead, the attributes are automatically rewritten to address the model directly, as this role-playing is a strength of modern \aclp{llm}. % TODO: citation
Thus, the attribute sentences will have the form \enquote{You are \ldots}.

The final prompt steering methods will combine the two previous methods and include both the group name and the most important attribute sentences in the system prompt.

\section{Activation Steering}
\label{sec:approach:steering:activation}
While the prompt steering methods are easy to implement, they have the disadvantage that they do not allow for fine-grained steering. Even when the most important attributes are included in the system prompt, there is no way to tell the model how strongly each attribute should influence the generated text. To solve this problem, this thesis proposes a method to steer the \ac{llm} by manipulating its activation space during inference following the work of \citet{turnerActivationAdditionSteering2024,rimsky-etal-2024-steering}.

The steering vectors are created without any training process, which reduces the required time significantly. For each dimension of the interpretable attribute vector, a separate steering vector is extracted.

\begin{figure}[ht]
  \input{figures/tikz/activation-steering-diagram.tex}
  \label{fig:activationSteering}
  \caption{Todo}
\end{figure}

\subsubsection{Extracting Steering Vectors}
The attribute that should be steered towards will be a part of the system prompt similar to the prompt attribute steering described in Section~\ref{sec:approach:steering:prompt}. Following that, the model predicts the next token in one forward pass. From that inference, the vectors after the activation functions of each layer are extracted and saved. The predicted token is not important during this process. % TODO: extract from activation functions or from residual streams?

To get the steering vector of a group, all attribute steering vectors need to be combined. For that, a softmax of the median attribute vector for a group is created. Afterward, each attribute steering vector is multiplied with the corresponding value of the softmax. Finally, all weighted steering vectors are added together.

Alternatively, instead of including all dimensions of the attribute vector, only the most important attributes can be used to create the group steering vector.

\subsubsection{Text Generation Steering}
\label{sec:approach:steering:activation}
To steer the text generation of a \acl{llm}, the computed steering vector is added to a layer of the model during the forward pass. The layer the vector is inserted into must be the same as the vectors that were combined to form the steering vector where taken from. The steering vector can be scaled with a factor \(\lambda\) to further control the strength of the steering effect.
Because the steering vector is extracted during the first forward pass, it is also inserted exclusively during the first forward pass (\cite{rimsky-etal-2024-steering}).
% \begin{itemize}
%   \item strength of the method is that no training is needed
%   \item the activation vectors will be extracted at each layer
%   \item for each attribute vector dimension, an activation vector is extracted
%   \item to create the steering vector for the layer x
%         \begin{enumerate}
%           \item take the attribute vector (for example for a group)
%           \item take a softmax
%           \item multiply the activation vector of each attribute sentence with the corresponding softmax value
%           \item add the weighted activation vectors together
%           \item multiply them with a factor \(\lambda\)
%         \end{enumerate}
%   \item the steering vector is added to the activation vector at layer x during the forward pass of a steered text generation
% \end{itemize}

% !TeX root = ..\..\thesis.tex
\chapter{Approach}
\label{sec:approach}

\section{Possible Improvement through Knowledge Attributes}
\label{sec:approach:knowledgeAttributes}
Where can I put this? Maybe a little bit in motivation, but probably mostly in evaluation and conclusion.


\section{Attribute Sentence Generation}
\label{sec:approach:attributeSentenceGeneration}

The attribute sentences that form the dimensions of the interpretable attribute vector are generated by prompting a \acf{llm} in a two-step procedure.

For step one, the \ac{llm} is presented with a zero-shot prompt to produce a description of the text. This step is repeated \num{\numPrompts} times, each time with a different prompt that focuses on a specific aspect of the text. \num{\numOpenPrompts} prompts (see Appendix~\ref{sec:appendix:openPrompts}) are relatively open and only give a loose direction on which style should be described by the model. \num{\numTargetPrompts} prompts (see Appendix~\ref{sec:appendix:targetPrompts}) are targeted towards an explicit stylistic feature. These prompts follow the work of \citet{patelLearningInterpretableStyle2023,tausczikPsychologicalMeaningWords2010} to get the model to focus on a broad variety of style that is important for the study of language.

In addition to these prompts aimed at stylistic features, there are \num{\numKnowledgePrompts} prompts (see Appendix~\ref{sec:appendix:knowledgePrompts}) which are focusing on the knowledge and experience of the author. While the background knowledge of the author is not as important for the group membership detection as the style of the text, it is helpful information for the steering task that is covered in later sections.

After generating the descriptions, the \ac{llm} is prompted a second time to rewrite them as a list of sentences. The model is instructed to write each sentence in a consistent form like \enquote{The author is \ldots} or \enquote{The author uses \ldots}. This process is shown in Figure~\ref{fig:attributeSentenceGeneration}.

\begin{figure}[ht]
  \input{content/04-approach/sentence-generation-diagram.tex}
  % TODO: better caption
  \caption{The process to generate attribute sentences.}
  \label{fig:attributeSentenceGeneration}
\end{figure}

In addition to the requirement towards the shape of the sentences, the model is instructed to avoid negations and examples since these both lead to increasing problems with the clustering process that is described in Section~\ref{sec:approach:clustering}.
Sentences that include examples are potentially problematic because it increases the likelihood of sentences which have the exact same content while being of significantly different shape; an example for this problem would be the sentences \enquote{The author uses filler words} and \enquote{The author uses filler words such as 'and', 'or' and 'furthermore'}. While this problem will be reduced by clustering similar sentences, the procedure is not perfect and will be more robust if the model avoids sentences with examples.

Negations on the other hand lead to the problem where the shape of the sentences will be too close while the content is very different. There is a high chance that the sentences \enquote{The author does use long sentences} and \enquote{The author does not use long sentences} will be clustered together because so much of them is the same even though they state the opposite of each other.
Additionally, the dimensions of the final attribute vector should not include any negated attributes since the expression \enquote{The author uses short sentences} is much clearer than \enquote{The author does not use long sentences}.

Since the model might produce sentences with negations or examples despite the prompt, each of the generated sentences is also checked automatically before further processing.

Per description, each distinct attribute sentence is recorded only once, even if the model generates it multiple times. This is done in case the model generates a bad answer where one sentence is repeated many times.


\section{Clustering}
\label{sec:approach:clustering}
A strength of the method to create attribute sentences described in Section~\ref{sec:approach:attributeSentenceGeneration} is the lack of constraints which results in a large variety of generated sentences. However, this leads to the problem that sentences with the same content can have many different shapes. An example for this would be the sentences \enquote{The author uses short and concise sentences.} and \enquote{The author uses concise and short sentences.}, which have exactly the same meaning while being considered as two completely different sentences by the procedure up to this point.

Because of that, it is more difficult to compare different input texts and to find texts that fit a similar feature attribute. Additionally, the selection of the dimension of the attribute vector described in Section~\ref{sec:approach:selection} could become more difficult as the number of times that an attribute has been used is obscured.
To solve this problem, my approach includes clustering the sentences by the cosine similarity of their embeddings which are produced by a sentence embedding model.

The clustering algorithm first computes a radius neighbor graph of all sentences. The sentences which have a sufficiently high cosine similarity are considered as being in the same cluster. Subsequently, the clusters are sorted by size and inspected from largest to smallest. If a sentence is included in one cluster, it is removed from all smaller ones. It is important to note that there is no minimum size for a cluster; if a sentence has no neighbors or every one of them is already part of a larger cluster that the cluster size is one.

The sentence that is the closest to the center of each cluster represents it. When the cluster is used, this sentence and its embedding is actually used.

This process is carried out seperatly for sentences that have been produced by style prompts and those produced by knowledge prompts (see Section~\ref{sec:approach:attributeSentenceGeneration}). Otherwise it could happen that a cluster includes lots of knowledge sentences but the center sentence is a style sentence, which could cause some problems in the later stages of the approach. % TODO: mention steering?
The resulting clusters are referred to as style clusters and knowledge clusters.


\section{Selecting the Attribute Vector Dimensions}
\label{sec:approach:selection}

Following the previous steps, there is now a synthetic dataset with lots of clusters. Since the final attribute vector will consist of significantly fewer dimensions, a process to select the best ones is needed. This selection is carried out in multiple steps.

\subsection{Selection of target attributes}
\label{sec:approach:selection:targetAttributes}
Following the work of \citet{patelLearningInterpretableStyle2023}, the first \num{\numTargetPrompts} dimensions of the attribute vector will be selected to correspond to the \num{\numTargetPrompts} target prompts which were described in section~\ref{sec:approach:attributeSentenceGeneration}.
This is done to ensure that the attribute vector has a robust foundation on some features that are manually selected for being relevant for stylistic research. The ability to automatically create most of the attribute vector is not significantly reduced since the target attributes only account for around \SI{10}{\percent} of its size. % TODO: 10% of unknown size of the vector?

These attributes are found by creating sentences of the form \enquote{The author uses <target>} and embedding them using an embedding model.
Afterward, for each sentence the style cluster with the highest cosine similarity is found. This cluster is then one of the target attributes of the vector. The knowledge clusters are not taken into account during this selection.


%!%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% here I am
\subsection{Filtering out attributes that occur too frequently}
\label{sec:approach:selection:filteringOccurance}
An important characteristic of all attributes that are part of the attribute vector is that they are as meaningful as possible and helpful to distinguish different groups. Because of that, this step in the cluster selection ensures that only clusters which are used to describe texts by less than \clusterMaxGroupRatio{} of the groups are selected. The cutoff ratio of groups follows the work of \citet{patelLearningInterpretableStyle2023}.

For the next steps of the cluster selection, it is also important that there are not too many possible clusters to select from, otherwise the computation would need too much time and memory. To quickly reduce the number of clusters, the number of times the cluster was used to describe answers is taken into account. The required number of times used is increased until the resulting number of clusters is smaller than \num{\maxClustersFirstSelection}. This number was chosen to be small enough for the following computation but big enough to enable a meaningful selection of attribute vector dimensions.

% TODO: include this?
A cluster could be used multiple times to describe the same answer. Although the sentence produced by each prompt is only counted once per prompt, multiple prompts could use the same or similar enough sentences to describe the answer. For this selection however, only the number of answers that have been described with the cluster are being counted and not how often the cluster was being used.

\subsection{Removing too similar Attributes}
\label{sec:approach:selection:removeSimilar}
To ensure that the attribute vector covers a wide range of attributes, it is important that the attributes do not cover too similar topics. This selection step fulfills this requirement by making sure that the attribute vector dimensions have a maximum cosine similarity of \num{\maxCosineSimilarity}. This process works by ordering the clusters by occurrence, selecting them one after the other and deleting all clusters that are too close to the ones that have already been selected.

In the work of \citeauthor{patelLearningInterpretableStyle2023}, they use a maximum cosine similarity of \num{0.8} as a cutoff. I decided to use a lower maximum similarity to increase the variance of the attribute vector dimensions and because of the clusters. % TODO: better explanation

\subsection{Final Selection} % TODO: better name?
\label{sec:approach:selection:finalSelection}
The first \num{\numTargetPrompts} dimensions of the attribute vector are the target attributes that were selection in Section~\ref{sec:approach:selection:targetAttributes}. The next \num{\minNumKnowledgePrompts} dimensions are knowledge clusters, that is clusters of sentences that were produced by knowledge prompts. The rest of the dimensions are selected in this step to be the ones with the highest range of accordance. % TODO: better word than accordance?

Range of accordance means that the range between the answers that match the attribute really well and the ones that do not match is as big as possible. This further increases the probability that the attributes are well suited to distinguish between different answers and groups.

First, the similarity between all clusters that remain after the first selection steps are computed. Afterward, the for each cluster and each answer the average similarity to all other clusters that have been used to describe that answer is computed. TODO:


% \begin{itemize}
%   \item \minNumKnowledgePrompts{} knowledge clusters are selected
%   \item compute similarities between clusters selected at this stage
%   \item for all clusters, compute the average similarity of all input texts by looking at the clusters that have been used to describe that input text
%   \item sort the clusters by the difference between the most and least matching input text
%   \item select the clusters with the highest difference
%   \item this is done because a style attribute will probably hold more meaningful information and is better suited to differentiate texts if it is very similar to some and very dissimilar to other texts
% \end{itemize}


\section{Training and Testing \acs{sfam}}
\label{sec:approach:sfam}

The goal of the method presented in this thesis is to create interpretable attribute vectors with values between \num{0} and \num{1} that correspond to real world values. To create these values, I will train a model that follows the \acf{sfam} that was presented by \citet{patelLearningInterpretableStyle2023}. It takes an attribute sentence and a text and outputs and agreement score that corresponds to how well the attribute sentence fits to the text.

\ac{sfam} is trained on the synthetic dataset which was created in earlier steps as described in Section~\ref{sec:approach:attributeSentenceGeneration}. The training data includes the unclustered knowledge and style sentences and the input texts that were described by them. There is however some preprocessing necessary, because just because an attribute sentence was not used to describe a text does not mean the text does not match the sentence. It could be that the text was described by a similar sentence or that the \ac{llm} just skipped a topic when describing one text.

The attribute sentences that are used for training are selected in a process similar to the one described in Section~\ref{sec:approach:selection:finalSelection}.
First, the similarity between all attribute sentences and all Attribute Vector dimensions are computed. Then, for each sentence and each text the average similarity to the dimensions that were used to describe the text is computed. The texts are then sorted by their similarity to the attribute sentence. If the sentence has been used to describe one of the \SI{1}{\percent} most similar texts, this text will be used as a positive training sample and the most dissimilar text where the sentence was not used to describe it is used as a negative training sample. Otherwise, the sentence will not be used for training.

The result dataset is balanced regarding positive and negative samples and has a high probability to only include sentences which actually fit the texts. % TODO: write better
The same process is used to create the validation and test dataset using different answers. % TODO: write here that the attribute sentences are largely distinct or later in experiments?

% \begin{itemize}
%   \item \ac{sfam} is a model that takes a style sentence and a text as input and produces an agreement score
%   \item training data
%         \begin{itemize}
%           % \item the \numStyleSentences{} style sentences are used for training % do not use numbers for approach
%           \item there are distinct sets of input texts for training, validation and test datasets
%           \item these lead to mostly different sentences (also the differences may be small)
%           \item of all sentences, the best are selected
%                 \begin{itemize}
%                   \item compute similarity to all style vector attributes (which are clusters)
%                   \item for each sentence, compute the most similar and most dissimilar input text according to the average similarity to all style attributes that have been used to describe that text (like the final selection of style vector attributes, see Section~\ref{sec:approach:selection}) % TODO: is there a more specific reference to a subsection?
%                   \item if one of the ten most similar input texts was actually described by the style sentence, it is chosen as a positive training sample and the least similar input text that was not described by the sentence as a negative sample
%                   \item otherwise, the sentence is not used for training
%                   \item the same is done for validation and test
%                 \end{itemize}
%         \end{itemize}
%   \item \ac{sfam} is a finetuned DeBERTaV3 model
%         \begin{itemize}
%           \item two fully connected layers with a ReLu in between % TODO: look up
%           \item finally a sigmoid activation function to produce values between 0 and 1
%         \end{itemize}
%   \item optional hyperparameter optimization (with optuna -> citation?) to discover optimal learning rate and weight decay
%   \item early stopping callback with patience of three
%   \item validation metric of accuracy
%   \item testing metric accuracy and f1
% \end{itemize}


\section{Training and Testing \acs{lisa}}
\label{sec:approach:lisa}
While \ac{sfam} produces the Attribute Vector with exactly the values that are required, it needs on forward pass per dimension of the vector. Even with an optimized model this takes a too long time for the most applications. The solution is to train an additional model which for the \acf{lisa} model proposed by \citet{patelLearningInterpretableStyle2023}, which gets a text as an input and produces the full Attribute Vector in one forward pass.

The training, validation and test data is created by using \ac{sfam} to create the Attribute Vectors of the corresponding texts and training \ac{lisa} as a regression model.

% \begin{itemize}
%   \item to get values for a style vector, the \num{\styleVectorSize} forward passes by \ac{sfam} would take too long for most practical applications
%   \item train an additional model that creates the whole vector in one forward pass
%   \item \ac{lisa} like \ac{sfam} is a finetuned DeBERTaV3 model
%         \begin{itemize}
%           \item two fully connected layers with a ReLu in between % TODO: look up
%           \item finally a sigmoid activation function to produce values between 0 and 1
%         \end{itemize}
% \end{itemize}

\section{Embedding Model}
\label{sec:approach:embedding}
The \ac{lisa} model produces an attribute vector where each dimension corresponds to one attribute sentence. The problem with this vector is that two vectors can not be easily compared to each other because the dimensions are not normalized and have different importances for the meaning of the vector.

Because of that, I train an embedding head for the \ac{lisa} model that produces attribute embeddings. While the dimensions of the embedding are not directly interpretable, they are derived directly from the interpretable attribute vectors and therefore do not lose much interpretability.

\section{Steering Text Generation}
In this thesis, I aim to combine the group membership task with the steering of \acp{llm} towards group specific explanations. Multiple different methods will be presented and compared to each other. The method split into to groups; changing the system prompt to steer the model and manipulating the output of the activation functions after selected layers.

\subsection{Prompt Steering}
\label{sec:approach:steering:prompt}
I will be looking at three different methods of changing the system prompt to adapt the way the \ac{llm} answers questions by the user to match a specific group.

The first and simplest way is to change the system prompt is to instruct the model to write for an explanation for a group. In this case, the system prompt includes the following sentence:
\begin{quote}
  You are an author that writes a helpful explanation for a group of <group>.
\end{quote}

While this method can not be influenced regarding the direction or strength of the steering effect, it is very easy to implement and will serve as a baseline to compare the other steering methods against.

For the second prompt steering approach, the data that is used to extract the features of the attribute vector as described in Section~\ref{sec:approach:attributeSentenceGeneration} will be used to determine the most important attributes that differentiate each group from all the others. The most important style and knowledge attribute will then be a part of the system prompt.

For the attributes to be able to be effectively used in the system prompt, they can not be of the form \enquote{The author is \ldots}. Instead, the attributes are automatically rewritten to address the model directly as this role playing is a strength of modern \aclp{llm}. % TODO: citation
Thus, the attribute sentences will have the form \enquote{You are \ldots}.

The final prompt steering methods will combine the two previous methods and include both the group name and the most important attribute sentences in the system prompt.

\section{Activation Steering}

While the prompt steering methods are easy to implement, they have the disadvantage that they do not allow for fine-grained steering. Even when the most important attributes are included in the system prompt, there is no way to tell the model how strongly each attribute should influence the generated text. To solve this problem, I propose a method to steer the \ac{llm} by manipulating its activation space during inference following the work of \citet{turnerActivationAdditionSteering2024,rimsky-etal-2024-steering}.

The steering vectors are created without any training process, which reduces the required time significantly. For each dimension of the interpretable attribute vector, a separate steering vector is extracted.

\begin{figure}
  \include{content/04-approach/activation-steering-diagram}
  \label{fig:activationSteering}
  \caption{Todo}
\end{figure}

\subsubsection{Extracting Steering Vectors}
The attribute that should be steered towards will be a part of the system prompt similar to the prompt attribute steering described in Section~\ref{sec:approach:steering:prompt}. Following that, the model predicts the next token in one forward pass. From that inference, the vectors after the activation functions of each layer are extracted and saved. The predicted token is not important during this process. % TODO: extract from activation functions or from residual streams?

To get to the steering vector of a group, all attribute steering vectors need to be combined. For that, a softmax of the median attribute vector for a group is created. Afterward, each attribute steering vector is multiplied with the corresponding value of the softmax. Finally, all weighted steering vectors are added together.

Alternatively, instead of including all dimensions of the attribute vector, only the most important attributes can be used to create the group steering vector.

\subsubsection{Text Generation Steering}




\label{sec:approach:steering:activation}
\begin{itemize}
  \item strength of the method is that no training is needed
  \item the activation vectors will be extracted at each layer
  \item for each attribute vector dimension, an activation vector is extracted
  \item to create the steering vector for the layer x
        \begin{enumerate}
          \item take the attribute vector (for example for a group)
          \item take a softmax
          \item multiply the activation vector of each attribute sentence with the corresponding softmax value
          \item add the weighted activation vectors together
          \item multiply them with a factor \(\lambda\)
        \end{enumerate}
  \item the steering vector is added to the activation vector at layer x during the forward pass of a steered text generation
\end{itemize}
\chapter{Approach}%
\label{sec:approach}

This thesis proposes a method for creating interpretable attribute vectors designed specifically for group membership detection, building upon the work of \citet{patelLearningInterpretableStyle2023}. The attribute vector is built on the traditional style vector and incorporates knowledge attributes that reflect the author's background knowledge and experience. These knowledge attributes can be instrumental in accurately classifying text (\cite{jin-etal-2022-deep}). Each dimension of the attribute vector represents a real-world attribute with values between \num{0} and \num{1}, corresponding to the extent to which the text expresses that attribute.

Additionally, various methods are proposed for steering the output of \acp{llm}, including a novel activation-based approach. The inclusion of knowledge attributes is especially beneficial for aligning content complexity and terminology use with the needs and expectations of different user groups.

\section{Creation of the Synthetic Dataset}%
\label{sec:approach:attributeSentenceGeneration}
This thesis requires a dataset of group-specific texts annotated with style and knowledge attributes to train and evaluate the models presented in later sections.
The synthetic dataset created for this thesis consists of group-specific answers annotated with style and knowledge attributes, based on the methodology described by \citet{patelLearningInterpretableStyle2023}. Attribute sentences are generated in two steps using this method. First, a zero-shot prompt describes an input text. This process is repeated \num{\numPrompts} times, each with a different focus. Of these prompts, \num{\numOpenPrompts} are open-ended (see Appendix~\ref{sec:appendix:openPrompts}), and \num{\numTargetPrompts} target specific stylistic features (see Appendix~\ref{sec:appendix:targetPrompts}). The prompts are based on previous work by \citet{patelLearningInterpretableStyle2023,tausczikPsychologicalMeaningWords2010} to ensure a broad, linguistically meaningful spectrum of style attributes. Additionally, in contrast to previous work, \num{\numKnowledgePrompts} knowledge prompts (see Appendix~\ref{sec:appendix:knowledgePrompts}) are used to capture the author's background knowledge and experience.

In the second step, the model is prompted to rewrite the generated descriptions as standardized attribute sentences. These sentences are typically in the form of \enquote{The author is \ldots} or \enquote{The author uses \ldots}. The entire process is illustrated in Figure~\ref{fig:attributeSentenceGeneration}. To improve the performance of later stages of the approach, the generated sentences are free of negations and do not include examples. This is accomplished by instructing the model not to use such constructions and by automatically verifying the generated sentences. This approach ensures consistency and facilitates better performance in subsequent tasks, aligning with the methods described by \citet{patelLearningInterpretableStyle2023}.

\begin{figure}[h!t]
  \input{figures/tikz/sentence-generation-diagram.tex}
  \caption{The two-step process to generate attribute sentences based on the work of \citet{patelLearningInterpretableStyle2023}. The inputs are group-specific answers from the Stack Exchange dataset (see Section~\ref{sec:datasets:stackex}). \Iac{llm} is prompted \num{\numPrompts} times to generate different descriptions of the input text. The prompts focus on different stylistic aspects and the knowledge of the author. Afterward, the \ac{llm} is prompted a second time to convert the descriptions into attribute sentences of a consistent shape.}%
  \label{fig:attributeSentenceGeneration}
\end{figure}

Sentences that include examples can cause clustering problems because they introduce surface-level differences despite conveying the same content. For instance, \enquote{The author uses filler words} and \enquote{The author uses filler words such as 'and', 'or' and 'furthermore'} may be semantically similar, but structurally they are different. Negations pose a different problem: while the sentence \enquote{The author does use long sentences} and its negated counterpart \enquote{The author does not use long sentences} are semantically opposite, they share much of the same structure, which can mislead clustering algorithm presented in the next section. Moreover, it is preferable for the dimensions of the final attribute vector to avoid negated sentences altogether. A positive phrasing such as \enquote{The author uses short sentences} is clearer and more interpretable than \enquote{The author does not use long sentences}. % Each attribute sentence is counted only once per description, even if it appears multiple times during generation.

\section{Clustering}%
\label{sec:approach:clustering}

A key advantage of the method described in Section~\ref{sec:approach:attributeSentenceGeneration} is its openness, which results in a wide variety of attribute sentences. However, this also means that semantically equivalent sentences may have very different syntactic forms. For example, \enquote{The author uses short and concise sentences.} and \enquote{The author uses concise and short sentences.} convey the same idea, yet they appear as distinct strings, which complicates comparison across texts.

To resolve this, the approach in this thesis extends the method of \citet{patelLearningInterpretableStyle2023} by clustering the attribute sentences based on the cosine similarity of their embeddings, which are computed using a sentence embedding model. Each cluster is then represented by the sentence closest to the cluster center, which is used in place of the entire cluster.

This clustering is performed separately for sentences generated from style prompts and those from knowledge prompts (see Section~\ref{sec:approach:attributeSentenceGeneration}). This ensures a clear distinction between style and knowledge attributes, resulting in two types of clusters: style clusters and knowledge clusters. From the total set of clusters, a selection based on their frequency in the dataset and the internal coherence of their embeddings is made. These selected clusters form the dimensions of the interpretable attribute vector.

\section{Model Training}%
\label{sec:approach:models}

To facilitate the automatic creation of interpretable attribute vectors, several language models are trained. The first model is the \acf{sfam}, which is based on the work of \citet{patelLearningInterpretableStyle2023}. This model receives an attribute sentence and a text as input and outputs an agreement score, which indicates how well the attribute sentence matches the content of the text. This scoring mechanism enables the construction of the interpretable attribute vector, with values between \num{0} and \num{1}, corresponding to real-world attribute meanings.

While \ac{sfam} produces highly accurate attribute vectors, it requires a separate forward pass for each attribute, making it computationally expensive and time-consuming. To address this limitation, an additional model, the \acf{lisa} model, also proposed by \citet{patelLearningInterpretableStyle2023}, is trained. This model takes a text as input and generates the entire attribute vector in a single forward pass.

However, the attribute vector produced by the \ac{lisa} model has is not normalized, which makes direct comparison between vectors difficult. To address this, an embedding head is trained on top of the \ac{lisa} model to produce normalized attribute embeddings. Although these embeddings are not directly interpretable, they are derived from the interpretable attribute vectors and thus retain much of the original interpretability.

\section{Steering Text Generation}%
\label{sec:approach:steering}

The goal of this section is to align the outputs of \acp{llm} with the stylistic and knowledge characteristics of specific user groups. Two types of steering methods are considered: prompt-based steering and activation-space manipulation. This dual approach allows for both high-level guidance and fine-grained control over the behavior of the model.

Three methods are introduced to guide the \ac{llm} through \textbf{prompt engineering}. The first method specifies the group directly in the system prompt and serves as a baseline that does not utilize the interpretable attribute vector. The second method extracts the most important attributes from the vector and incorporates them into the prompt. The third method combines the group identity and key attributes to provide more comprehensive guidance. Prompt-based steering is advantageous because it is easy to implement and does not require changes to the underlying model.

Additionally, this thesis introduces a novel technique for steering the model through \textbf{activation steering}. This method extends the work of \citet{konenStyleVectorsSteering2024,turnerActivationAdditionSteering2024,rimsky-etal-2024-steering} by using the most relevant attributes from the interpretable attribute vector for a specific group to guide the model toward corresponding stylistic and knowledge features. This technique addresses the limitations of prompt steering by enabling more precise control over the model's output.

The activation steering method operates as follows, as illustrated in Figure~\ref{fig:activationSteering}. First, the model is prompted to adopt the style or knowledge conveyed by an attribute sentence. This causes the conceptual content of the attribute to be encoded in the model's activation space. The activation vectors at the end of each layer of the model are then extracted during a forward pass. To perform the steering, a steering vector is created for specific layers by combining activation vectors for multiple attributes, weighted by their values in the median attribute vector for a group. The median attribute vector is extracted from the group-specific texts in the synthetic dataset presented in Section~\ref{sec:approach:attributeSentenceGeneration}. The steering vector is then multiplied by a scaling factor \(\lambda\) and added to the model's activation space during inference. Importantly, the same layer from which the activations were originally extracted is also used for injecting the steering vector.


\begin{figure}[hb]
  \centering
  \scalebox{0.95}{
    \input{figures/tikz/activation-steering-diagram.tex}
  }
  \caption{This figure illustrates the process of extracting activation vectors that can be used to steer \iac{llm}. The basis for the extraction is the interpretable attribute vector presented in this thesis, where each of the dimensions corresponds to a real-world concept in the form of an attribute sentence. The model is queried for each of these sentences. The sentence is changed from the form \enquote{The author uses \ldots} to \enquote{You use \ldots} and presented as part of the system prompt. The model then performs one forward pass, from which the activation vector is extracted at the end of each layer. These vectors encode the concept of the attribute sentence (\cite{konenStyleVectorsSteering2024,turnerActivationAdditionSteering2024,rimsky-etal-2024-steering}). To create the steering vector, the activation vectors are weighted by the corresponding softmax value of the attribute vector and added together. While this thesis uses the median group attribute vector extracted from the synthetic dataset (see Section~\ref{sec:approach:attributeSentenceGeneration}) as the basis for steering towards group-specific explanations, it would be possible to use the attribute vector of a single text to mimic its style.}%
  \label{fig:activationSteering}
\end{figure}

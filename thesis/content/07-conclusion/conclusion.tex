\chapter{Conclusion}
\label{sec:conclusion}
This thesis presents a comprehensive framework for interpretable text representation and the steering of \acp{llm} towards group-specific explanations, structured as one continuous pipeline. Starting with group-specific texts, the process results in the generation of group-specific explanations using various steering techniques, including a novel activation-based approach. During this procedure, an interpretable attribute vector that can be used for group membership detection is produced.

A key component of this work is the creation of a synthetic dataset that is annotated with style and knowledge attributes. This dataset supports the training and evaluation of models throughout the thesis.

The experiments conducted as part of this thesis have established that augmenting the style vector proposed by \citet{patelLearningInterpretableStyle2023} with knowledge attributes improves the performance of group membership detection. Additionally, the experiments demonstrated the effectiveness of the automatic creation of the attribute vector and the \ac{lisa} model responsible for generating it.

The results have also shown that steering via prompt engineering benefits from the information encoded in the interpretable attribute vector. This enables more tailored and relevant \ac{llm} outputs when targeting specific groups.

Additionally, the experiments confirm the effectiveness of the novel, activation-based steering approach in producing group-specific explanations. This method allows for precise control over the output of the model by adjusting its internal activations based on the interpretable attribute vector.

However, the thesis reveals that achieving reliable results with the \ac{lisa} model requires a large volume of group-specific texts. Furthermore, it demonstrates that the advantages of the steering methods are not equally distributed among all groups; certain groups exhibit more significant improvements than others.

Overall, the work presented in this thesis contributes to the field of interpretable representation learning and opens up new opportunities for personalized language generation using \aclp{llm}.


\section{Limitations and Future Work}
Although this thesis makes significant contributions to the areas of group membership detection and \ac{llm} steering, several limitations remain, and numerous open research questions and potential applications provide valuable directions for future work.
One such direction for future research involves comparing \ac{sfam} to human judgments, as demonstrated by \citet{patelLearningInterpretableStyle2023}, to provide a more comprehensive evaluation of the model. Further experiments are also needed to determine if changing the number of important attributes used for prompt- and activation-based steering influences their effectiveness (see Section~\ref{sec:approach:steering}).

A more extensive optimization of the hyperparameters for activation-based steering could provide valuable insights into which layers and scaling factors are most effective in altering the activation space of \acp{llm} (see Section~\ref{sec:approach:steering:activation}). A probing study similar to the one conducted by \citet{konenStyleVectorsSteering2024} could support this, as it was able to find the layers of the model that process concepts of specific complexity levels. Another open question is whether there is a relationship between knowledge attributes being less important for a group and a reduced steering performance towards that group, which the experiments results presented in Section~\ref{sec:evaluation:steering:groups} suggest. Finally, as discussed in Section~\ref{sec:evaluation:steering:groups}, it remains unclear why different steering methods perform better for different groups and if there are ways to improve steering performance for all groups.

There are also several limitations to the current work. One significant limitation is the reliance on group-specific data from internet forums (see Section~\ref{sec:datasets}) that may include noise. Using data guaranteed to be written by specific groups could improve the performance of the presented approach. Additionally, as is often the case in machine learning and natural language processing, using more data could improve results, particularly for training the \ac{lisa} model (see Section~\ref{sec:evaluation:models}).
% TODO: include this?
% Another limitation is that the evaluation of steering methods currently depends on metrics that use the same most important attributes. Using metrics independent of these attributes could provide a more robust assessment of steering quality.

Beyond the contributions already made, the approach developed in this thesis has the potential to be used for additional applications. For example, the steering methods could use the attribute vector of a single text instead of the median attribute vector of a group. This would replicate the style of that individual text. Another possible application is implementing a hybrid method combining the approach presented in this thesis with a manually selected set of attributes, such as sentence length or use of special characters, like emojis, similar to the StyloMetrix approach presented by \citet{okulskaStyloMetrixOpensourceMultilingual2023}. This combined approach would leverage the strengths of each method: the high interpretability of the manually selected attributes and the awareness of the experiences of the author and independence from predefined attributes of the attribute vector presented in this thesis.

\chapter{Conclusion}
\label{sec:conclusion}
This thesis presents a comprehensive framework for interpretable text representation and the steering of \acp{llm} towards group-specific explanations, structured as one continuous pipeline. Starting with group-specific texts, the process results in the generation of group-specific explanations using various steering techniques, including a novel activation-based approach. During this procedure, an interpretable attribute vector that can be used for group membership detection is produced.

A key component of this work is the creation of a synthetic dataset that is annotated with style and knowledge attributes. This dataset supports the training and evaluation of models throughout the thesis.

The experiments conducted as part of this thesis have established that augmenting the style vector proposed by \citet{patelLearningInterpretableStyle2023} with knowledge attributes improves the performance of group membership detection. Additionally, the experiments demonstrated the effectiveness of the automatic creation of the attribute vector and the \ac{lisa} model responsible for generating it.

The results have also shown that steering via prompt engineering benefits from the information encoded in the interpretable attribute vector. This enables more tailored and relevant \ac{llm} outputs when targeting specific groups.

Additionally, the experiments confirm the effectiveness of the novel, activation-based steering approach in producing group-specific explanations. This method allows for precise control over the output of the model by adjusting its internal activations based on the interpretable attribute vector.

However, the thesis reveals that achieving reliable results with the \ac{lisa} model requires a large volume of group-specific texts. Furthermore, it demonstrates that the advantages of the steering methods are not equally distributed among all groups; certain groups exhibit more significant improvements than others.

Overall, the work presented in this thesis contributes to the field of interpretable representation learning and opens up new opportunities for personalized language generation using \aclp{llm}.


\section{Limitations and Future Work}
\begin{itemize}
  \item while this thesis contributes to the fields of group membership detection and \ac{llm} steering, it is important
\end{itemize}
\begin{itemize}
  \item use data for the experiments that is guaranteed to be written by specific groups
  \item use more and better data (often a possible improvement in ML/NLP)
  \item probing study to find the best layer for activation steering
  \item further experiments, if a different number of important attributes has an effect on steering (prompt steering and activation steering)
  \item compare \ac{sfam} to human judgments like \citet{patelLearningInterpretableStyle2023}
  \item activation steering not based on the median attribute vector of a group but the attribute vector of a single text to replicate its style.
  \item Multidimensional Analysis (MDA) \newline
        MDA assesses linguistic features across multiple dimensions to profile text styles. For instance, Biber's MDA framework evaluates texts based on factors like formality, narrative style, and informational density. Recent advancements include Neurobiber, a transformer-based system that predicts 96 stylistic features efficiently, facilitating large-scale stylometric research.
  \item implement a mix of the approach presented in this thesis with selected attributes (maybe in place of the targeted attributes) (see StyloMetrix by \citet{okulskaStyloMetrixOpensourceMultilingual2023})
  \item evaluate the steering methods on metrics that do not depend on the same most important attributes
  \item larger HPO for activation steering
  \item is there a connection between less important knowledge attributes and worse steering performance?
  \item why are different steering methods better for different groups (see Section~\ref{sec:evaluation:steering:groups})?
\end{itemize}

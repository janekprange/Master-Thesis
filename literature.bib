@online{konenStyleVectorsSteering2024,
  title = {Style {{Vectors}} for {{Steering Generative Large Language Model}}},
  author = {Konen, Kai and Jentzsch, Sophie and Diallo, Diaoulé and Schütt, Peer and Bensch, Oliver and Baff, Roxanne El and Opitz, Dominik and Hecking, Tobias},
  date = {2024-02-02},
  eprint = {2402.01618},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.01618},
  url = {http://arxiv.org/abs/2402.01618},
  urldate = {2024-09-24},
  abstract = {This research explores strategies for steering the output of large language models (LLMs) towards specific styles, such as sentiment, emotion, or writing style, by adding style vectors to the activations of hidden layers during text generation. We show that style vectors can be simply computed from recorded layer activations for input texts in a specific style in contrast to more complex training-based approaches. Through a series of experiments, we demonstrate the effectiveness of activation engineering using such style vectors to influence the style of generated text in a nuanced and parameterisable way, distinguishing it from prompt engineering. The presented research constitutes a significant step towards developing more adaptive and effective AI-empowered interactive systems.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\janek\\Zotero\\storage\\Y3GW4FBK\\Konen et al. - 2024 - Style Vectors for Steering Generative Large Language Model.pdf;C\:\\Users\\janek\\Zotero\\storage\\EY4AAIKN\\2402.html}
}

@online{turnerActivationAdditionSteering2024a,
  title = {Activation {{Addition}}: {{Steering Language Models Without Optimization}}},
  shorttitle = {Activation {{Addition}}},
  author = {Turner, Alexander Matt and Thiergart, Lisa and Leech, Gavin and Udell, David and Vazquez, Juan J. and Mini, Ulisse and MacDiarmid, Monte},
  date = {2024-06-04},
  eprint = {2308.10248},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2308.10248},
  url = {http://arxiv.org/abs/2308.10248},
  urldate = {2024-09-24},
  abstract = {Reliably controlling the behavior of large language models is a pressing open problem. Existing methods include supervised finetuning, reinforcement learning from human feedback, prompt engineering and guided decoding. We instead investigate activation engineering: modifying activations at inference-time to predictably alter model behavior. We bias the forward pass with a 'steering vector' implicitly specified through natural language. Past work learned these steering vectors; our Activation Addition (ActAdd) method instead computes them by taking activation differences resulting from pairs of prompts. We demonstrate ActAdd on a range of LLMs (LLaMA-3, OPT, GPT-2, and GPT-J), obtaining SOTA on detoxification and negative-to-positive sentiment control. Our approach yields inference-time control over high-level properties of output like topic and sentiment while preserving performance on off-target tasks. ActAdd takes far less compute and implementation effort than finetuning or RLHF, allows users control through natural language, and its computational overhead (as a fraction of inference time) appears stable or improving over increasing model size.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\janek\\Zotero\\storage\\5YKWUG6N\\Turner et al. - 2024 - Activation Addition Steering Language Models Without Optimization.pdf;C\:\\Users\\janek\\Zotero\\storage\\DN4U4DM2\\2308.html}
}

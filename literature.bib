@online{alhafniPersonalizedTextGeneration2024,
  title = {Personalized {{Text Generation}} with {{Fine-Grained Linguistic Control}}},
  author = {Alhafni, Bashar and Kulkarni, Vivek and Kumar, Dhruv and Raheja, Vipul},
  date = {2024-02-07},
  url = {https://arxiv.org/abs/2402.04914v1},
  urldate = {2024-09-27},
  abstract = {As the text generation capabilities of large language models become increasingly prominent, recent studies have focused on controlling particular aspects of the generated text to make it more personalized. However, most research on controllable text generation focuses on controlling the content or modeling specific high-level/coarse-grained attributes that reflect authors' writing styles, such as formality, domain, or sentiment. In this paper, we focus on controlling fine-grained attributes spanning multiple linguistic dimensions, such as lexical and syntactic attributes. We introduce a novel benchmark to train generative models and evaluate their ability to generate personalized text based on multiple fine-grained linguistic attributes. We systematically investigate the performance of various large language models on our benchmark and draw insights from the factors that impact their performance. We make our code, data, and pretrained models publicly available.},
  langid = {english},
  organization = {arXiv.org},
  file = {C:\Users\janek\Zotero\storage\IWAUDYLL\Alhafni et al. - 2024 - Personalized Text Generation with Fine-Grained Linguistic Control.pdf}
}

@online{doddapaneniUserEmbeddingModel2024,
  title = {User {{Embedding Model}} for {{Personalized Language Prompting}}},
  author = {Doddapaneni, Sumanth and Sayana, Krishna and Jash, Ambarish and Sodhi, Sukhdeep and Kuzmin, Dima},
  date = {2024-01-09},
  eprint = {2401.04858},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2401.04858},
  urldate = {2024-09-27},
  abstract = {Modeling long histories plays a pivotal role in enhancing recommendation systems, allowing to capture user's evolving preferences, resulting in more precise and personalized recommendations. In this study we tackle the challenges of modeling long user histories for preference understanding in natural language. Specifically, we introduce a new User Embedding Module (UEM) that efficiently processes user history in free-form text by compressing and representing them as embeddings, to use them as soft prompts to a LM. Our experiments demonstrate the superior capability of this approach in handling significantly longer histories compared to conventional text based prompting methods, yielding substantial improvements in predictive performance. The main contribution of this research is to demonstrate the ability to bias language models with user signals represented as embeddings.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Machine Learning},
  file = {C\:\\Users\\janek\\Zotero\\storage\\PBA2TXBM\\Doddapaneni et al. - 2024 - User Embedding Model for Personalized Language Prompting.pdf;C\:\\Users\\janek\\Zotero\\storage\\ZDG4PZFU\\2401.html}
}

@online{konenStyleVectorsSteering2024,
  title = {Style {{Vectors}} for {{Steering Generative Large Language Model}}},
  author = {Konen, Kai and Jentzsch, Sophie and Diallo, Diaoulé and Schütt, Peer and Bensch, Oliver and Baff, Roxanne El and Opitz, Dominik and Hecking, Tobias},
  date = {2024-02-02},
  url = {https://arxiv.org/abs/2402.01618v1},
  urldate = {2024-09-27},
  abstract = {This research explores strategies for steering the output of large language models (LLMs) towards specific styles, such as sentiment, emotion, or writing style, by adding style vectors to the activations of hidden layers during text generation. We show that style vectors can be simply computed from recorded layer activations for input texts in a specific style in contrast to more complex training-based approaches. Through a series of experiments, we demonstrate the effectiveness of activation engineering using such style vectors to influence the style of generated text in a nuanced and parameterisable way, distinguishing it from prompt engineering. The presented research constitutes a significant step towards developing more adaptive and effective AI-empowered interactive systems.},
  langid = {english},
  organization = {arXiv.org},
  file = {C:\Users\janek\Zotero\storage\VETF26EU\Konen et al. - 2024 - Style Vectors for Steering Generative Large Language Model.pdf}
}

@online{patelLearningInterpretableStyle2023,
  title = {Learning {{Interpretable Style Embeddings}} via {{Prompting LLMs}}},
  author = {Patel, Ajay and Rao, Delip and Kothary, Ansh and McKeown, Kathleen and Callison-Burch, Chris},
  date = {2023-10-09},
  eprint = {2305.12696},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.12696},
  url = {http://arxiv.org/abs/2305.12696},
  urldate = {2024-09-27},
  abstract = {Style representation learning builds content-independent representations of author style in text. Stylometry, the analysis of style in text, is often performed by expert forensic linguists and no large dataset of stylometric annotations exists for training. Current style representation learning uses neural methods to disentangle style from content to create style vectors, however, these approaches result in uninterpretable representations, complicating their usage in downstream applications like authorship attribution where auditing and explainability is critical. In this work, we use prompting to perform stylometry on a large number of texts to create a synthetic dataset and train human-interpretable style representations we call LISA embeddings. We release our synthetic stylometry dataset and our interpretable style models as resources.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\janek\\Zotero\\storage\\CIUFXHT9\\Patel et al. - 2023 - Learning Interpretable Style Embeddings via Prompting LLMs.pdf;C\:\\Users\\janek\\Zotero\\storage\\B383WVHI\\2305.html}
}

@online{subramaniExtractingLatentSteering2022,
  title = {Extracting {{Latent Steering Vectors}} from {{Pretrained Language Models}}},
  author = {Subramani, Nishant and Suresh, Nivedita and Peters, Matthew E.},
  date = {2022-05-10},
  eprint = {2205.05124},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.05124},
  url = {http://arxiv.org/abs/2205.05124},
  urldate = {2024-09-27},
  abstract = {Prior work on controllable text generation has focused on learning how to control language models through trainable decoding, smart-prompt design, or fine-tuning based on a desired objective. We hypothesize that the information needed to steer the model to generate a target sentence is already encoded within the model. Accordingly, we explore a different approach altogether: extracting latent vectors directly from pretrained language model decoders without fine-tuning. Experiments show that there exist steering vectors, which, when added to the hidden states of the language model, generate a target sentence nearly perfectly ({$>$} 99 BLEU) for English sentences from a variety of domains. We show that vector arithmetic can be used for unsupervised sentiment transfer on the Yelp sentiment benchmark, with performance comparable to models tailored to this task. We find that distances between steering vectors reflect sentence similarity when evaluated on a textual similarity benchmark (STS-B), outperforming pooled hidden states of models. Finally, we present an analysis of the intrinsic properties of the steering vectors. Taken together, our results suggest that frozen LMs can be effectively controlled through their latent steering space.},
  pubstate = {prepublished},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\janek\\Zotero\\storage\\L89NKEG9\\Subramani et al. - 2022 - Extracting Latent Steering Vectors from Pretrained Language Models.pdf;C\:\\Users\\janek\\Zotero\\storage\\8D3HFBUF\\2205.html}
}

@online{turnerActivationAdditionSteering2024,
  title = {Activation {{Addition}}: {{Steering Language Models Without Optimization}}},
  shorttitle = {Activation {{Addition}}},
  author = {Turner, Alexander Matt and Thiergart, Lisa and Leech, Gavin and Udell, David and Vazquez, Juan J. and Mini, Ulisse and MacDiarmid, Monte},
  date = {2024-06-04},
  eprint = {2308.10248},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2308.10248},
  urldate = {2024-09-27},
  abstract = {Reliably controlling the behavior of large language models is a pressing open problem. Existing methods include supervised finetuning, reinforcement learning from human feedback, prompt engineering and guided decoding. We instead investigate activation engineering: modifying activations at inference-time to predictably alter model behavior. We bias the forward pass with a 'steering vector' implicitly specified through natural language. Past work learned these steering vectors; our Activation Addition (ActAdd) method instead computes them by taking activation differences resulting from pairs of prompts. We demonstrate ActAdd on a range of LLMs (LLaMA-3, OPT, GPT-2, and GPT-J), obtaining SOTA on detoxification and negative-to-positive sentiment control. Our approach yields inference-time control over high-level properties of output like topic and sentiment while preserving performance on off-target tasks. ActAdd takes far less compute and implementation effort than finetuning or RLHF, allows users control through natural language, and its computational overhead (as a fraction of inference time) appears stable or improving over increasing model size.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\janek\\Zotero\\storage\\UWUCEGH9\\Turner et al. - 2024 - Activation Addition Steering Language Models Without Optimization.pdf;C\:\\Users\\janek\\Zotero\\storage\\D8I89JDU\\2308.html}
}

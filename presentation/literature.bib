@inproceedings{10.1007/978-3-642-29047-3_27,
  title = {Implicit Group Membership Detection in Online Text: Analysis and Applications},
  booktitle = {Social Computing, Behavioral - Cultural Modeling and Prediction},
  author = {Ellen, Jeffrey and Kaina, Joan and Parameswaran, Shibin},
  editor = {Yang, Shanchieh Jay and Greenberg, Ariel M. and Endsley, Mica},
  date = {2012},
  pages = {222--230},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  abstract = {Our thesis is that members of the same group have shared tendencies and nuances in communication style and substance, particularly online. In this paper, we dicuss some potential applications of accuarate authorship affiliation technology. We also discuss related work in similar author identification efforts and the research issues that currently exist when trying to perform automated authorship affiliation. We provide quantitative results from our recent Machine Learning experimenation using Support Vector Machines as some initial validation of our theory. In this paper, we applied our work towards the task of classifying website forum posts by the affiliation of their author. We discuss in detail the stylometric features we used to perform the automated classification and split the original features into individual groups to isolate their respective contributions and/or discriminating capability. Our results show promise towards automating group representation, an important first step in studying group formation.},
  isbn = {978-3-642-29047-3},
  langid = {english}
}

@online{alhafniPersonalizedTextGeneration2024,
  title = {Personalized Text Generation with Fine-Grained Linguistic Control},
  author = {Alhafni, Bashar and Kulkarni, Vivek and Kumar, Dhruv and Raheja, Vipul},
  date = {2024-02-07},
  eprint = {2402.04914},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.04914},
  url = {http://arxiv.org/abs/2402.04914},
  urldate = {2024-09-28},
  abstract = {As the text generation capabilities of large language models become increasingly prominent, recent studies have focused on controlling particular aspects of the generated text to make it more personalized. However, most research on controllable text generation focuses on controlling the content or modeling specific high-level/coarse-grained attributes that reflect authors' writing styles, such as formality, domain, or sentiment. In this paper, we focus on controlling fine-grained attributes spanning multiple linguistic dimensions, such as lexical and syntactic attributes. We introduce a novel benchmark to train generative models and evaluate their ability to generate personalized text based on multiple fine-grained linguistic attributes. We systematically investigate the performance of various large language models on our benchmark and draw insights from the factors that impact their performance. We make our code, data, and pretrained models publicly available.},
  langid = {english},
  pubstate = {prepublished},
  version = {1},
  file = {C\:\\Users\\janek\\Zotero\\storage\\LK6K3YYG\\Alhafni et al. - 2024 - Personalized Text Generation with Fine-Grained Linguistic Control.pdf;C\:\\Users\\janek\\Zotero\\storage\\7FLRNLEZ\\2402.html},
  keywords = {Computer Science - Computation and Language,generation steering,preprint,recommended}
}

@online{alshomaryLatentSpaceInterpretation2024,
  title = {Latent Space Interpretation for Stylistic Analysis and Explainable Authorship Attribution},
  author = {Alshomary, Milad and Ri, Narutatsu and Apidianaki, Marianna and Patel, Ajay and Muresan, Smaranda and McKeown, Kathleen},
  date = {2024-09-11},
  eprint = {2409.07072},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2409.07072},
  url = {http://arxiv.org/abs/2409.07072},
  urldate = {2024-11-14},
  abstract = {Recent state-of-the-art authorship attribution methods learn authorship representations of texts in a latent, non-interpretable space, hindering their usability in real-world applications. Our work proposes a novel approach to interpreting these learned embeddings by identifying representative points in the latent space and utilizing LLMs to generate informative natural language descriptions of the writing style of each point. We evaluate the alignment of our interpretable space with the latent one and find that it achieves the best prediction agreement compared to other baselines. Additionally, we conduct a human evaluation to assess the quality of these style descriptions, validating their utility as explanations for the latent space. Finally, we investigate whether human performance on the challenging AA task improves when aided by our system's explanations, finding an average improvement of around +20\% in accuracy.},
  langid = {english},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\QVHQNXPB\\Alshomary et al. - 2024 - Latent space interpretation for stylistic analysis and explainable authorship attribution.pdf;C\:\\Users\\janek\\Zotero\\storage\\9SU9DMPX\\2409.html},
  keywords = {authorship attribution,Computer Science - Computation and Language,preprint,reading complete,recommended}
}

@book{birdNaturalLanguageProcessing2009,
  title = {Natural Language Processing with {{Python}}},
  author = {Bird, Steven and Klein, Ewan and Loper, Edward},
  date = {2009},
  edition = {1st ed},
  publisher = {O'Reilly},
  location = {Beijing ; Cambridge [Mass.]},
  abstract = {This is an introduction to natural language processing, which supports a variety of language technologies, from predictive text and email filtering to automatic summarization and translation},
  isbn = {978-0-596-51649-9},
  pagetotal = {479},
  keywords = {Natural language processing (Computer science),programming_library,Python (Computer program language),Python <Programmiersprache>,Sprachverarbeitung},
  annotation = {OCLC: ocn301885973}
}

@online{doddapaneniUserEmbeddingModel2024,
  title = {User Embedding Model for Personalized Language Prompting},
  author = {Doddapaneni, Sumanth and Sayana, Krishna and Jash, Ambarish and Sodhi, Sukhdeep and Kuzmin, Dima},
  date = {2024-01-09},
  eprint = {2401.04858},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2401.04858},
  urldate = {2024-09-27},
  abstract = {Modeling long histories plays a pivotal role in enhancing recommendation systems, allowing to capture user's evolving preferences, resulting in more precise and personalized recommendations. In this study we tackle the challenges of modeling long user histories for preference understanding in natural language. Specifically, we introduce a new User Embedding Module (UEM) that efficiently processes user history in free-form text by compressing and representing them as embeddings, to use them as soft prompts to a LM. Our experiments demonstrate the superior capability of this approach in handling significantly longer histories compared to conventional text based prompting methods, yielding substantial improvements in predictive performance. The main contribution of this research is to demonstrate the ability to bias language models with user signals represented as embeddings.},
  langid = {english},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\PBA2TXBM\\Doddapaneni et al. - 2024 - User Embedding Model for Personalized Language Prompting.pdf;C\:\\Users\\janek\\Zotero\\storage\\ZDG4PZFU\\2401.html},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Machine Learning,preprint,recommended}
}

@online{dubeyLlama3Herd2024,
  title = {The Llama 3 Herd of Models},
  author = {Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and Goyal, Anirudh and Hartshorn, Anthony and Yang, Aobo and Mitra, Archi and Sravankumar, Archie and Korenev, Artem and Hinsvark, Arthur and Rao, Arun and Zhang, Aston and Rodriguez, Aurelien and Gregerson, Austen and Spataru, Ava and Roziere, Baptiste and Biron, Bethany and Tang, Binh and Chern, Bobbie and Caucheteux, Charlotte and Nayak, Chaya and Bi, Chloe and Marra, Chris and McConnell, Chris and Keller, Christian and Touret, Christophe and Wu, Chunyang and Wong, Corinne and Ferrer, Cristian Canton and Nikolaidis, Cyrus and Allonsius, Damien and Song, Daniel and Pintz, Danielle and Livshits, Danny and Esiobu, David and Choudhary, Dhruv and Mahajan, Dhruv and Garcia-Olano, Diego and Perino, Diego and Hupkes, Dieuwke and Lakomkin, Egor and AlBadawy, Ehab and Lobanova, Elina and Dinan, Emily and Smith, Eric Michael and Radenovic, Filip and Zhang, Frank and Synnaeve, Gabriel and Lee, Gabrielle and Anderson, Georgia Lewis and Nail, Graeme and Mialon, Gregoire and Pang, Guan and Cucurell, Guillem and Nguyen, Hailey and Korevaar, Hannah and Xu, Hu and Touvron, Hugo and Zarov, Iliyan and Ibarra, Imanol Arrieta and Kloumann, Isabel and Misra, Ishan and Evtimov, Ivan and Copet, Jade and Lee, Jaewon and Geffert, Jan and Vranes, Jana and Park, Jason and Mahadeokar, Jay and Shah, Jeet and family=Linde, given=Jelmer, prefix=van der, useprefix=false and Billock, Jennifer and Hong, Jenny and Lee, Jenya and Fu, Jeremy and Chi, Jianfeng and Huang, Jianyu and Liu, Jiawen and Wang, Jie and Yu, Jiecao and Bitton, Joanna and Spisak, Joe and Park, Jongsoo and Rocca, Joseph and Johnstun, Joshua and Saxe, Joshua and Jia, Junteng and Alwala, Kalyan Vasuden and Upasani, Kartikeya and Plawiak, Kate and Li, Ke and Heafield, Kenneth and Stone, Kevin and El-Arini, Khalid and Iyer, Krithika and Malik, Kshitiz and Chiu, Kuenley and Bhalla, Kunal and Rantala-Yeary, Lauren and family=Maaten, given=Laurens, prefix=van der, useprefix=false and Chen, Lawrence and Tan, Liang and Jenkins, Liz and Martin, Louis and Madaan, Lovish and Malo, Lubo and Blecher, Lukas and Landzaat, Lukas and family=Oliveira, given=Luke, prefix=de, useprefix=false and Muzzi, Madeline and Pasupuleti, Mahesh and Singh, Mannat and Paluri, Manohar and Kardas, Marcin and Oldham, Mathew and Rita, Mathieu and Pavlova, Maya and Kambadur, Melanie and Lewis, Mike and Si, Min and Singh, Mitesh Kumar and Hassan, Mona and Goyal, Naman and Torabi, Narjes and Bashlykov, Nikolay and Bogoychev, Nikolay and Chatterji, Niladri and Duchenne, Olivier and Çelebi, Onur and Alrassy, Patrick and Zhang, Pengchuan and Li, Pengwei and Vasic, Petar and Weng, Peter and Bhargava, Prajjwal and Dubal, Pratik and Krishnan, Praveen and Koura, Punit Singh and Xu, Puxin and He, Qing and Dong, Qingxiao and Srinivasan, Ragavan and Ganapathy, Raj and Calderer, Ramon and Cabral, Ricardo Silveira and Stojnic, Robert and Raileanu, Roberta and Girdhar, Rohit and Patel, Rohit and Sauvestre, Romain and Polidoro, Ronnie and Sumbaly, Roshan and Taylor, Ross and Silva, Ruan and Hou, Rui and Wang, Rui and Hosseini, Saghar and Chennabasappa, Sahana and Singh, Sanjay and Bell, Sean and Kim, Seohyun Sonia and Edunov, Sergey and Nie, Shaoliang and Narang, Sharan and Raparthy, Sharath and Shen, Sheng and Wan, Shengye and Bhosale, Shruti and Zhang, Shun and Vandenhende, Simon and Batra, Soumya and Whitman, Spencer and Sootla, Sten and Collot, Stephane and Gururangan, Suchin and Borodinsky, Sydney and Herman, Tamar and Fowler, Tara and Sheasha, Tarek and Georgiou, Thomas and Scialom, Thomas and Speckbacher, Tobias and Mihaylov, Todor and Xiao, Tong and Karn, Ujjwal and Goswami, Vedanuj and Gupta, Vibhor and Ramanathan, Vignesh and Kerkez, Viktor and Gonguet, Vincent and Do, Virginie and Vogeti, Vish and Petrovic, Vladan and Chu, Weiwei and Xiong, Wenhan and Fu, Wenyin and Meers, Whitney and Martinet, Xavier and Wang, Xiaodong and Tan, Xiaoqing Ellen and Xie, Xinfeng and Jia, Xuchao and Wang, Xuewei and Goldschlag, Yaelle and Gaur, Yashesh and Babaei, Yasmine and Wen, Yi and Song, Yiwen and Zhang, Yuchen and Li, Yue and Mao, Yuning and Coudert, Zacharie Delpierre and Yan, Zheng and Chen, Zhengxing and Papakipos, Zoe and Singh, Aaditya and Grattafiori, Aaron and Jain, Abha and Kelsey, Adam and Shajnfeld, Adam and Gangidi, Adithya and Victoria, Adolfo and Goldstand, Ahuva and Menon, Ajay and Sharma, Ajay and Boesenberg, Alex and Vaughan, Alex and Baevski, Alexei and Feinstein, Allie and Kallet, Amanda and Sangani, Amit and Yunus, Anam and Lupu, Andrei and Alvarado, Andres and Caples, Andrew and Gu, Andrew and Ho, Andrew and Poulton, Andrew and Ryan, Andrew and Ramchandani, Ankit and Franco, Annie and Saraf, Aparajita and Chowdhury, Arkabandhu and Gabriel, Ashley and Bharambe, Ashwin and Eisenman, Assaf and Yazdan, Azadeh and James, Beau and Maurer, Ben and Leonhardi, Benjamin and Huang, Bernie and Loyd, Beth and Paola, Beto De and Paranjape, Bhargavi and Liu, Bing and Wu, Bo and Ni, Boyu and Hancock, Braden and Wasti, Bram and Spence, Brandon and Stojkovic, Brani and Gamido, Brian and Montalvo, Britt and Parker, Carl and Burton, Carly and Mejia, Catalina and Wang, Changhan and Kim, Changkyu and Zhou, Chao and Hu, Chester and Chu, Ching-Hsiang and Cai, Chris and Tindal, Chris and Feichtenhofer, Christoph and Civin, Damon and Beaty, Dana and Kreymer, Daniel and Li, Daniel and Wyatt, Danny and Adkins, David and Xu, David and Testuggine, Davide and David, Delia and Parikh, Devi and Liskovich, Diana and Foss, Didem and Wang, Dingkang and Le, Duc and Holland, Dustin and Dowling, Edward and Jamil, Eissa and Montgomery, Elaine and Presani, Eleonora and Hahn, Emily and Wood, Emily and Brinkman, Erik and Arcaute, Esteban and Dunbar, Evan and Smothers, Evan and Sun, Fei and Kreuk, Felix and Tian, Feng and Ozgenel, Firat and Caggioni, Francesco and Guzmán, Francisco and Kanayet, Frank and Seide, Frank and Florez, Gabriela Medina and Schwarz, Gabriella and Badeer, Gada and Swee, Georgia and Halpern, Gil and Thattai, Govind and Herman, Grant and Sizov, Grigory and Guangyi and Zhang and Lakshminarayanan, Guna and Shojanazeri, Hamid and Zou, Han and Wang, Hannah and Zha, Hanwen and Habeeb, Haroun and Rudolph, Harrison and Suk, Helen and Aspegren, Henry and Goldman, Hunter and Damlaj, Ibrahim and Molybog, Igor and Tufanov, Igor and Veliche, Irina-Elena and Gat, Itai and Weissman, Jake and Geboski, James and Kohli, James and Asher, Japhet and Gaya, Jean-Baptiste and Marcus, Jeff and Tang, Jeff and Chan, Jennifer and Zhen, Jenny and Reizenstein, Jeremy and Teboul, Jeremy and Zhong, Jessica and Jin, Jian and Yang, Jingyi and Cummings, Joe and Carvill, Jon and Shepard, Jon and McPhie, Jonathan and Torres, Jonathan and Ginsburg, Josh and Wang, Junjie and Wu, Kai and U, Kam Hou and Saxena, Karan and Prasad, Karthik and Khandelwal, Kartikay and Zand, Katayoun and Matosich, Kathy and Veeraraghavan, Kaushik and Michelena, Kelly and Li, Keqian and Huang, Kun and Chawla, Kunal and Lakhotia, Kushal and Huang, Kyle and Chen, Lailin and Garg, Lakshya and A, Lavender and Silva, Leandro and Bell, Lee and Zhang, Lei and Guo, Liangpeng and Yu, Licheng and Moshkovich, Liron and Wehrstedt, Luca and Khabsa, Madian and Avalani, Manav and Bhatt, Manish and Tsimpoukelli, Maria and Mankus, Martynas and Hasson, Matan and Lennie, Matthew and Reso, Matthias and Groshev, Maxim and Naumov, Maxim and Lathi, Maya and Keneally, Meghan and Seltzer, Michael L. and Valko, Michal and Restrepo, Michelle and Patel, Mihir and Vyatskov, Mik and Samvelyan, Mikayel and Clark, Mike and Macey, Mike and Wang, Mike and Hermoso, Miquel Jubert and Metanat, Mo and Rastegari, Mohammad and Bansal, Munish and Santhanam, Nandhini and Parks, Natascha and White, Natasha and Bawa, Navyata and Singhal, Nayan and Egebo, Nick and Usunier, Nicolas and Laptev, Nikolay Pavlovich and Dong, Ning and Zhang, Ning and Cheng, Norman and Chernoguz, Oleg and Hart, Olivia and Salpekar, Omkar and Kalinli, Ozlem and Kent, Parkin and Parekh, Parth and Saab, Paul and Balaji, Pavan and Rittner, Pedro and Bontrager, Philip and Roux, Pierre and Dollar, Piotr and Zvyagina, Polina and Ratanchandani, Prashant and Yuvraj, Pritish and Liang, Qian and Alao, Rachad and Rodriguez, Rachel and Ayub, Rafi and Murthy, Raghotham and Nayani, Raghu and Mitra, Rahul and Li, Raymond and Hogan, Rebekkah and Battey, Robin and Wang, Rocky and Maheswari, Rohan and Howes, Russ and Rinott, Ruty and Bondu, Sai Jayesh and Datta, Samyak and Chugh, Sara and Hunt, Sara and Dhillon, Sargun and Sidorov, Sasha and Pan, Satadru and Verma, Saurabh and Yamamoto, Seiji and Ramaswamy, Sharadh and Lindsay, Shaun and Lindsay, Shaun and Feng, Sheng and Lin, Shenghao and Zha, Shengxin Cindy and Shankar, Shiva and Zhang, Shuqiang and Zhang, Shuqiang and Wang, Sinong and Agarwal, Sneha and Sajuyigbe, Soji and Chintala, Soumith and Max, Stephanie and Chen, Stephen and Kehoe, Steve and Satterfield, Steve and Govindaprasad, Sudarshan and Gupta, Sumit and Cho, Sungmin and Virk, Sunny and Subramanian, Suraj and Choudhury, Sy and Goldman, Sydney and Remez, Tal and Glaser, Tamar and Best, Tamara and Kohler, Thilo and Robinson, Thomas and Li, Tianhe and Zhang, Tianjun and Matthews, Tim and Chou, Timothy and Shaked, Tzook and Vontimitta, Varun and Ajayi, Victoria and Montanez, Victoria and Mohan, Vijai and Kumar, Vinay Satish and Mangla, Vishal and Albiero, Vítor and Ionescu, Vlad and Poenaru, Vlad and Mihailescu, Vlad Tiberiu and Ivanov, Vladimir and Li, Wei and Wang, Wenchen and Jiang, Wenwen and Bouaziz, Wes and Constable, Will and Tang, Xiaocheng and Wang, Xiaofang and Wu, Xiaojian and Wang, Xiaolan and Xia, Xide and Wu, Xilun and Gao, Xinbo and Chen, Yanjun and Hu, Ye and Jia, Ye and Qi, Ye and Li, Yenda and Zhang, Yilin and Zhang, Ying and Adi, Yossi and Nam, Youngjin and Yu and Wang and Hao, Yuchen and Qian, Yundi and He, Yuzi and Rait, Zach and DeVito, Zachary and Rosnbrick, Zef and Wen, Zhaoduo and Yang, Zhenyu and Zhao, Zhiwei},
  date = {2024-08-15},
  eprint = {2407.21783},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2407.21783},
  url = {http://arxiv.org/abs/2407.21783},
  urldate = {2024-11-05},
  abstract = {Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.},
  langid = {english},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\UGRLPNCF\\Dubey et al. - 2024 - The llama 3 herd of models.pdf;C\:\\Users\\janek\\Zotero\\storage\\XPRJXDHF\\2407.html},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,preprint,programming_library}
}

@article{gilardiChatGPTOutperformsCrowdworkers2023,
  title = {{{ChatGPT}} Outperforms Crowd-Workers for Text-Annotation Tasks},
  author = {Gilardi, Fabrizio and Alizadeh, Meysam and Kubli, Maël},
  date = {2023-07-25},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc. Natl. Acad. Sci.},
  volume = {120},
  number = {30},
  eprint = {2303.15056},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {e2305016120},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.2305016120},
  url = {http://arxiv.org/abs/2303.15056},
  urldate = {2024-09-29},
  abstract = {Many NLP applications require manual data annotations for a variety of tasks, notably to train classifiers or evaluate the performance of unsupervised models. Depending on the size and degree of complexity, the tasks may be conducted by crowd-workers on platforms such as MTurk as well as trained annotators, such as research assistants. Using a sample of 2,382 tweets, we demonstrate that ChatGPT outperforms crowd-workers for several annotation tasks, including relevance, stance, topics, and frames detection. Specifically, the zero-shot accuracy of ChatGPT exceeds that of crowd-workers for four out of five tasks, while ChatGPT's intercoder agreement exceeds that of both crowd-workers and trained annotators for all tasks. Moreover, the per-annotation cost of ChatGPT is less than \$0.003 -- about twenty times cheaper than MTurk. These results show the potential of large language models to drastically increase the efficiency of text classification.},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Computers and Society},
  file = {C\:\\Users\\janek\\Zotero\\storage\\I359IUK3\\Gilardi et al. - 2023 - ChatGPT outperforms crowd-workers for text-annotation tasks.pdf;C\:\\Users\\janek\\Zotero\\storage\\5WURXX9I\\2303.html}
}

@article{harris2020array,
  title = {Array Programming with {{NumPy}}},
  author = {Harris, Charles R. and Millman, K. Jarrod and family=Walt, given=Stéfan J., prefix=van der, useprefix=true and Gommers, Ralf and Virtanen, Pauli and Cournapeau, David and Wieser, Eric and Taylor, Julian and Berg, Sebastian and Smith, Nathaniel J. and Kern, Robert and Picus, Matti and Hoyer, Stephan and family=Kerkwijk, given=Marten H., prefix=van, useprefix=true and Brett, Matthew and Haldane, Allan and family=Río, given=Jaime Fernández, prefix=del, useprefix=true and Wiebe, Mark and Peterson, Pearu and Gérard-Marchant, Pierre and Sheppard, Kevin and Reddy, Tyler and Weckesser, Warren and Abbasi, Hameer and Gohlke, Christoph and Oliphant, Travis E.},
  date = {2020-09},
  journaltitle = {Nature},
  volume = {585},
  number = {7825},
  pages = {357--362},
  publisher = {{Springer Science and Business Media LLC}},
  doi = {10.1038/s41586-020-2649-2},
  url = {https://doi.org/10.1038/s41586-020-2649-2},
  langid = {english},
  keywords = {programming_library}
}

@online{honovichUnnaturalInstructionsTuning2022,
  title = {Unnatural Instructions: Tuning Language Models with (Almost) {{No}} Human Labor},
  shorttitle = {Unnatural Instructions},
  author = {Honovich, Or and Scialom, Thomas and Levy, Omer and Schick, Timo},
  date = {2022-12-19},
  eprint = {2212.09689},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2212.09689},
  url = {http://arxiv.org/abs/2212.09689},
  urldate = {2024-09-29},
  abstract = {Instruction tuning enables pretrained language models to perform new tasks from inference-time natural language descriptions. These approaches rely on vast amounts of human supervision in the form of crowdsourced datasets or user interactions. In this work, we introduce Unnatural Instructions: a large dataset of creative and diverse instructions, collected with virtually no human labor. We collect 64,000 examples by prompting a language model with three seed examples of instructions and eliciting a fourth. This set is then expanded by prompting the model to rephrase each instruction, creating a total of approximately 240,000 examples of instructions, inputs, and outputs. Experiments show that despite containing a fair amount of noise, training on Unnatural Instructions rivals the effectiveness of training on open-source manually-curated datasets, surpassing the performance of models such as T0++ and Tk-Instruct across various benchmarks. These results demonstrate the potential of model-generated data as a cost-effective alternative to crowdsourcing for dataset expansion and diversification.},
  langid = {english},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\Q92JKR3J\\Honovich et al. - 2022 - Unnatural instructions tuning language models with (almost) No human labor.pdf;C\:\\Users\\janek\\Zotero\\storage\\865QE4HB\\2212.html},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,preprint}
}

@online{huangLargeLanguageModels2022,
  title = {Large Language Models Can Self-Improve},
  author = {Huang, Jiaxin and Gu, Shixiang Shane and Hou, Le and Wu, Yuexin and Wang, Xuezhi and Yu, Hongkun and Han, Jiawei},
  date = {2022-10-25},
  eprint = {2210.11610},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2210.11610},
  url = {http://arxiv.org/abs/2210.11610},
  urldate = {2024-09-29},
  abstract = {Large Language Models (LLMs) have achieved excellent performances in various tasks. However, fine-tuning an LLM requires extensive supervision. Human, on the other hand, may improve their reasoning abilities by self-thinking without external inputs. In this work, we demonstrate that an LLM is also capable of self-improving with only unlabeled datasets. We use a pre-trained LLM to generate "high-confidence" rationale-augmented answers for unlabeled questions using Chain-of-Thought prompting and self-consistency, and fine-tune the LLM using those self-generated solutions as target outputs. We show that our approach improves the general reasoning ability of a 540B-parameter LLM (74.4\%-{$>$}82.1\% on GSM8K, 78.2\%-{$>$}83.0\% on DROP, 90.0\%-{$>$}94.4\% on OpenBookQA, and 63.4\%-{$>$}67.9\% on ANLI-A3) and achieves state-of-the-art-level performance, without any ground truth label. We conduct ablation studies and show that fine-tuning on reasoning is critical for self-improvement.},
  langid = {english},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\ZWTBE7SI\\Huang et al. - 2022 - Large language models can self-improve.pdf;C\:\\Users\\janek\\Zotero\\storage\\ML59CG85\\2210.html},
  keywords = {Computer Science - Computation and Language,preprint}
}

@inproceedings{ijcai2020p526,
  title = {Text Style Transfer via Learning Style Instance Supported Latent Space},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, {{IJCAI-20}}},
  author = {Yi, Xiaoyuan and Liu, Zhenghao and Li, Wenhao and Sun, Maosong},
  editor = {Bessiere, Christian},
  date = {2020-07},
  pages = {3801--3807},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  doi = {10.24963/ijcai.2020/526},
  url = {https://doi.org/10.24963/ijcai.2020/526},
  langid = {english},
  keywords = {style transfer}
}

@article{jin-etal-2022-deep,
  title = {Deep Learning for Text Style Transfer: A Survey},
  author = {Jin, Di and Jin, Zhijing and Hu, Zhiting and Vechtomova, Olga and Mihalcea, Rada},
  date = {2022-03},
  journaltitle = {Computational Linguistics},
  shortjournal = {Comput. Linguist.},
  volume = {48},
  number = {1},
  pages = {155--205},
  publisher = {MIT Press},
  location = {Cambridge, MA},
  doi = {10.1162/coli_a_00426},
  url = {https://aclanthology.org/2022.cl-1.6},
  abstract = {Text style transfer is an important task in natural language generation, which aims to control certain attributes in the generated text, such as politeness, emotion, humor, and many others. It has a long history in the field of natural language processing, and recently has re-gained significant attention thanks to the promising performance brought by deep neural models. In this article, we present a systematic survey of the research on neural text style transfer, spanning over 100 representative articles since the first neural text style transfer work in 2017. We discuss the task formulation, existing datasets and subtasks, evaluation, as well as the rich methodologies in the presence of parallel and non-parallel data. We also provide discussions on a variety of important topics regarding the future development of this task.1},
  langid = {english},
  file = {C:\Users\janek\Zotero\storage\8L7FMW3F\Jin et al. - 2022 - Deep learning for text style transfer a survey.pdf}
}

@online{konenStyleVectorsSteering2024,
  title = {Style Vectors for Steering Generative Large Language Model},
  author = {Konen, Kai and Jentzsch, Sophie and Diallo, Diaoulé and Schütt, Peer and Bensch, Oliver and Baff, Roxanne El and Opitz, Dominik and Hecking, Tobias},
  date = {2024-02-02},
  eprint = {2402.01618},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2402.01618},
  url = {http://arxiv.org/abs/2402.01618},
  urldate = {2024-09-28},
  abstract = {This research explores strategies for steering the output of large language models (LLMs) towards specific styles, such as sentiment, emotion, or writing style, by adding style vectors to the activations of hidden layers during text generation. We show that style vectors can be simply computed from recorded layer activations for input texts in a specific style in contrast to more complex training-based approaches. Through a series of experiments, we demonstrate the effectiveness of activation engineering using such style vectors to influence the style of generated text in a nuanced and parameterisable way, distinguishing it from prompt engineering. The presented research constitutes a significant step towards developing more adaptive and effective AI-empowered interactive systems.},
  langid = {english},
  pubstate = {prepublished},
  version = {1},
  file = {C\:\\Users\\janek\\Zotero\\storage\\U5R9YU3J\\Konen et al. - 2024 - Style vectors for steering generative large language model.pdf;C\:\\Users\\janek\\Zotero\\storage\\MMSHLJ2Z\\2402.html},
  keywords = {Computer Science - Computation and Language,generation steering,preprint,reading complete,recommended}
}

@online{lesterPowerScaleParameterEfficient2021,
  title = {The {{Power}} of {{Scale}} for {{Parameter-Efficient Prompt Tuning}}},
  author = {Lester, Brian and Al-Rfou, Rami and Constant, Noah},
  date = {2021-09-02},
  eprint = {2104.08691},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2104.08691},
  url = {http://arxiv.org/abs/2104.08691},
  urldate = {2024-11-25},
  abstract = {In this work, we explore "prompt tuning", a simple yet effective mechanism for learning "soft prompts" to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signal from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3's "few-shot" learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method "closes the gap" and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant in that large models are costly to share and serve, and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed "prefix tuning" of Li and Liang (2021), and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer, as compared to full model tuning.},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\8TDKAHC7\\Lester et al. - 2021 - The Power of Scale for Parameter-Efficient Prompt Tuning.pdf;C\:\\Users\\janek\\Zotero\\storage\\5YSWQKUE\\2104.html},
  keywords = {Computer Science - Computation and Language,generation steering,preprint}
}

@inproceedings{mckinney-proc-scipy-2010,
  title = {Data {{Structures}} for {{Statistical Computing}} in {{Python}}},
  booktitle = {Proceedings of the 9th {{Python}} in {{Science Conference}}},
  author = {McKinney, Wes},
  editor = {family=Walt, given=Stéfan, prefix=van der, useprefix=true and Millman, Jarrod},
  date = {2010},
  pages = {56--61},
  doi = {10.25080/Majora-92bf1922-00a},
  keywords = {programming_library}
}

@inproceedings{NIPS2017_3f5ee243,
  title = {Attention Is All You Need},
  booktitle = {Advances in Neural Information Processing Systems},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Łukasz and Polosukhin, Illia},
  editor = {Guyon, I. and Luxburg, U. Von and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  date = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  url = {https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf}
}

@online{parkLinearRepresentationHypothesis2024,
  title = {The Linear Representation Hypothesis and the Geometry of Large Language Models},
  author = {Park, Kiho and Choe, Yo Joong and Veitch, Victor},
  date = {2024-07-17},
  eprint = {2311.03658},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2311.03658},
  url = {http://arxiv.org/abs/2311.03658},
  urldate = {2024-12-01},
  abstract = {Informally, the 'linear representation hypothesis' is the idea that high-level concepts are represented linearly as directions in some representation space. In this paper, we address two closely related questions: What does "linear representation" actually mean? And, how do we make sense of geometric notions (e.g., cosine similarity or projection) in the representation space? To answer these, we use the language of counterfactuals to give two formalizations of "linear representation", one in the output (word) representation space, and one in the input (sentence) space. We then prove these connect to linear probing and model steering, respectively. To make sense of geometric notions, we use the formalization to identify a particular (non-Euclidean) inner product that respects language structure in a sense we make precise. Using this causal inner product, we show how to unify all notions of linear representation. In particular, this allows the construction of probes and steering vectors using counterfactual pairs. Experiments with LLaMA-2 demonstrate the existence of linear representations of concepts, the connection to interpretation and control, and the fundamental role of the choice of inner product.},
  langid = {english},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\6QI4XZD2\\Park et al. - 2024 - The Linear Representation Hypothesis and the Geometry of Large Language Models.pdf;C\:\\Users\\janek\\Zotero\\storage\\7M5N6QPX\\2311.html},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,preprint,Statistics - Machine Learning}
}

@online{paszkePyTorchImperativeStyle2019,
  title = {{{PyTorch}}: {{An Imperative Style}}, {{High-Performance Deep Learning Library}}},
  shorttitle = {{{PyTorch}}},
  author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Köpf, Andreas and Yang, Edward and DeVito, Zach and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  date = {2019-12-03},
  eprint = {1912.01703},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.1912.01703},
  url = {http://arxiv.org/abs/1912.01703},
  urldate = {2024-11-04},
  abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs. In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance. We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\WXUSI4PU\\Paszke et al. - 2019 - PyTorch An Imperative Style, High-Performance Deep Learning Library.pdf;C\:\\Users\\janek\\Zotero\\storage\\J6JCU35G\\1912.html},
  keywords = {Computer Science - Machine Learning,Computer Science - Mathematical Software,preprint,programming_library,Statistics - Machine Learning}
}

@online{patelLearningInterpretableStyle2023,
  title = {Learning Interpretable Style Embeddings via Prompting {{LLMs}}},
  author = {Patel, Ajay and Rao, Delip and Kothary, Ansh and McKeown, Kathleen},
  date = {2023-10-09},
  eprint = {2305.12696},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2305.12696},
  url = {http://arxiv.org/abs/2305.12696},
  urldate = {2024-09-27},
  abstract = {Style representation learning builds content-independent representations of author style in text. Stylometry, the analysis of style in text, is often performed by expert forensic linguists and no large dataset of stylometric annotations exists for training. Current style representation learning uses neural methods to disentangle style from content to create style vectors, however, these approaches result in uninterpretable representations, complicating their usage in downstream applications like authorship attribution where auditing and explainability is critical. In this work, we use prompting to perform stylometry on a large number of texts to create a synthetic dataset and train human-interpretable style representations we call LISA embeddings. We release our synthetic stylometry dataset and our interpretable style models as resources.},
  langid = {english},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\CIUFXHT9\\Patel et al. - 2023 - Learning Interpretable Style Embeddings via Prompting LLMs.pdf;C\:\\Users\\janek\\Zotero\\storage\\B383WVHI\\2305.html},
  keywords = {authorship attribution,Computer Science - Computation and Language,preprint,reading complete,recommended}
}

@inproceedings{petroni-etal-2021-kilt,
  title = {{{KILT}}: A Benchmark for Knowledge Intensive Language Tasks},
  booktitle = {Proceedings of the 2021 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  author = {Petroni, Fabio and Piktus, Aleksandra and Fan, Angela and Lewis, Patrick and Yazdani, Majid and De Cao, Nicola and Thorne, James and Jernite, Yacine and Karpukhin, Vladimir and Maillard, Jean and Plachouras, Vassilis and Rocktäschel, Tim and Riedel, Sebastian},
  date = {2021-06},
  pages = {2523--2544},
  publisher = {Association for Computational Linguistics},
  location = {Online},
  doi = {10.18653/v1/2021.naacl-main.200},
  url = {https://aclanthology.org/2021.naacl-main.200},
  langid = {english},
  keywords = {citation only}
}

@software{reback2020pandas,
  title = {Pandas-Dev/Pandas: {{Pandas}}},
  author = {family=team, given=The, prefix=pandas development, useprefix=false},
  date = {2020-02},
  doi = {10.5281/zenodo.3509134},
  url = {https://doi.org/10.5281/zenodo.3509134},
  organization = {Zenodo},
  version = {latest},
  keywords = {programming_library}
}

@online{reimersSentenceBERTSentenceEmbeddings2019,
  title = {Sentence-{{BERT}}: {{Sentence Embeddings}} Using {{Siamese BERT-Networks}}},
  shorttitle = {Sentence-{{BERT}}},
  author = {Reimers, Nils and Gurevych, Iryna},
  date = {2019-08-27},
  eprint = {1908.10084},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.1908.10084},
  url = {http://arxiv.org/abs/1908.10084},
  urldate = {2024-11-04},
  abstract = {BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations (\textasciitilde 65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\JNXUC4XS\\Reimers und Gurevych - 2019 - Sentence-BERT Sentence Embeddings using Siamese BERT-Networks.pdf;C\:\\Users\\janek\\Zotero\\storage\\GG825WFB\\1908.html},
  keywords = {Computer Science - Computation and Language,preprint,programming_library}
}

@inproceedings{rimsky-etal-2024-steering,
  title = {Steering Llama 2 via Contrastive Activation Addition},
  booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: {{Long}} Papers)},
  author = {Rimsky, Nina and Gabrieli, Nick and Schulz, Julian and Tong, Meg and Hubinger, Evan and Turner, Alexander},
  editor = {Ku, Lun-Wei and Martins, Andre and Srikumar, Vivek},
  date = {2024-08},
  pages = {15504--15522},
  publisher = {Association for Computational Linguistics},
  location = {Bangkok, Thailand},
  doi = {10.18653/v1/2024.acl-long.828},
  url = {https://aclanthology.org/2024.acl-long.828},
  abstract = {We introduce Contrastive Activation Addition (CAA), a method for steering language models by modifying their activations during forward passes. CAA computes “steering vectors” by averaging the difference in residual stream activations between pairs of positive and negative examples of a particular behavior, such as factual versus hallucinatory responses. During inference, these steering vectors are added at all token positions after the user's prompt with either a positive or negative coefficient, allowing precise control over the degree of the targeted behavior. We evaluate CAA's effectiveness on Llama 2 Chat using multiple-choice behavioral question datasets and open-ended generation tasks. We demonstrate that CAA significantly alters model behavior, is effective over and on top of traditional methods like finetuning and system prompt design, and minimally reduces capabilities. Moreover, we gain deeper insights into CAA's mechanisms by employing various activation space interpretation methods. CAA accurately steers model outputs and sheds light on how high-level concepts are represented in Large Language Models (LLMs).},
  langid = {english},
  keywords = {generation steering},
  file = {C:\Users\janek\Zotero\storage\5Y2WCPLB\Rimsky et al. - 2024 - Steering llama 2 via contrastive activation addition.pdf}
}

@inproceedings{rivera-soto-etal-2021-learning,
  title = {Learning Universal Authorship Representations},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  author = {Rivera-Soto, Rafael A. and Miano, Olivia Elizabeth and Ordonez, Juanita and Chen, Barry Y. and Khan, Aleem and Bishop, Marcus and Andrews, Nicholas},
  editor = {Moens, Marie-Francine and Huang, Xuanjing and Specia, Lucia and Yih, Scott Wen-tau},
  date = {2021-11},
  pages = {913--919},
  publisher = {Association for Computational Linguistics},
  location = {Online and Punta Cana, Dominican Republic},
  doi = {10.18653/v1/2021.emnlp-main.70},
  url = {https://aclanthology.org/2021.emnlp-main.70},
  abstract = {Determining whether two documents were composed by the same author, also known as authorship verification, has traditionally been tackled using statistical methods. Recently, authorship representations learned using neural networks have been found to outperform alternatives, particularly in large-scale settings involving hundreds of thousands of authors. But do such representations learned in a particular domain transfer to other domains? Or are these representations inherently entangled with domain-specific features? To study these questions, we conduct the first large-scale study of cross-domain transfer for authorship verification considering zero-shot transfers involving three disparate domains: Amazon reviews, fanfiction short stories, and Reddit comments. We find that although a surprising degree of transfer is possible between certain domains, it is not so successful between others. We examine properties of these domains that influence generalization and propose simple but effective methods to improve transfer.},
  langid = {english},
  keywords = {authorship attribution}
}

@online{rooeinKnowYourAudience2023,
  title = {Know Your Audience: Do {{LLMs}} Adapt to Different Age and Education Levels?},
  shorttitle = {Know Your Audience},
  author = {Rooein, Donya and Curry, Amanda Cercas and Hovy, Dirk},
  date = {2023-12-04},
  eprint = {2312.02065},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2312.02065},
  url = {http://arxiv.org/abs/2312.02065},
  urldate = {2025-04-04},
  abstract = {Large language models (LLMs) offer a range of new possibilities, including adapting the text to different audiences and their reading needs. But how well do they adapt? We evaluate the readability of answers generated by four state-of-the-art LLMs (commercial and open-source) to science questions when prompted to target different age groups and education levels. To assess the adaptability of LLMs to diverse audiences, we compare the readability scores of the generated responses against the recommended comprehension level of each age and education group. We find large variations in the readability of the answers by different LLMs. Our results suggest LLM answers need to be better adapted to the intended audience demographics to be more comprehensible. They underline the importance of enhancing the adaptability of LLMs in education settings to cater to diverse age and education levels. Overall, current LLMs have set readability ranges and do not adapt well to different audiences, even when prompted. That limits their potential for educational purposes.},
  langid = {english},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\MW7TYX7M\\Rooein et al. - 2023 - Know Your Audience Do LLMs Adapt to Different Age and Education Levels.pdf;C\:\\Users\\janek\\Zotero\\storage\\JITDKMFD\\2312.html},
  keywords = {citation only,Computer Science - Artificial Intelligence,Computer Science - Computation and Language,preprint}
}

@online{subramaniExtractingLatentSteering2022,
  title = {Extracting Latent Steering Vectors from Pretrained Language Models},
  author = {Subramani, Nishant and Suresh, Nivedita and Peters, Matthew E.},
  date = {2022-05-10},
  eprint = {2205.05124},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2205.05124},
  url = {http://arxiv.org/abs/2205.05124},
  urldate = {2024-09-27},
  abstract = {Prior work on controllable text generation has focused on learning how to control language models through trainable decoding, smart-prompt design, or fine-tuning based on a desired objective. We hypothesize that the information needed to steer the model to generate a target sentence is already encoded within the model. Accordingly, we explore a different approach altogether: extracting latent vectors directly from pretrained language model decoders without fine-tuning. Experiments show that there exist steering vectors, which, when added to the hidden states of the language model, generate a target sentence nearly perfectly ({$>$} 99 BLEU) for English sentences from a variety of domains. We show that vector arithmetic can be used for unsupervised sentiment transfer on the Yelp sentiment benchmark, with performance comparable to models tailored to this task. We find that distances between steering vectors reflect sentence similarity when evaluated on a textual similarity benchmark (STS-B), outperforming pooled hidden states of models. Finally, we present an analysis of the intrinsic properties of the steering vectors. Taken together, our results suggest that frozen LMs can be effectively controlled through their latent steering space.},
  langid = {english},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\L89NKEG9\\Subramani et al. - 2022 - Extracting Latent Steering Vectors from Pretrained Language Models.pdf;C\:\\Users\\janek\\Zotero\\storage\\8D3HFBUF\\2205.html},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,generation steering,preprint,reading complete,recommended}
}

@article{tausczikPsychologicalMeaningWords2010,
  title = {The Psychological Meaning of Words: {{LIWC}} and Computerized Text Analysis Methods},
  shorttitle = {The Psychological Meaning of Words},
  author = {Tausczik, Yla R. and Pennebaker, James W.},
  date = {2010-03},
  journaltitle = {Journal of Language and Social Psychology},
  shortjournal = {J. Lang. Soc. Psychol.},
  volume = {29},
  number = {1},
  pages = {24--54},
  issn = {0261-927X, 1552-6526},
  doi = {10.1177/0261927X09351676},
  url = {https://journals.sagepub.com/doi/10.1177/0261927X09351676},
  urldate = {2025-03-25},
  abstract = {We are in the midst of a technological revolution whereby, for the first time, researchers can link daily word use to a broad array of real-world behaviors. This article reviews several computerized text analysis methods and describes how Linguistic Inquiry and Word Count (LIWC) was created and validated. LIWC is a transparent text analysis program that counts words in psychologically meaningful categories. Empirical results using LIWC demonstrate its ability to detect meaning in a wide variety of experimental settings, including to show attentional focus, emotionality, social relationships, thinking styles, and individual differences.},
  langid = {english},
  keywords = {citation only}
}

@online{turnerActivationAdditionSteering2024,
  title = {Activation Addition: Steering Language Models without Optimization},
  shorttitle = {Activation Addition},
  author = {Turner, Alexander Matt and Thiergart, Lisa and Leech, Gavin and Udell, David and Vazquez, Juan J. and Mini, Ulisse and MacDiarmid, Monte},
  date = {2024-06-04},
  eprint = {2308.10248},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2308.10248},
  urldate = {2024-09-27},
  abstract = {Reliably controlling the behavior of large language models is a pressing open problem. Existing methods include supervised finetuning, reinforcement learning from human feedback, prompt engineering and guided decoding. We instead investigate activation engineering: modifying activations at inference-time to predictably alter model behavior. We bias the forward pass with a 'steering vector' implicitly specified through natural language. Past work learned these steering vectors; our Activation Addition (ActAdd) method instead computes them by taking activation differences resulting from pairs of prompts. We demonstrate ActAdd on a range of LLMs (LLaMA-3, OPT, GPT-2, and GPT-J), obtaining SOTA on detoxification and negative-to-positive sentiment control. Our approach yields inference-time control over high-level properties of output like topic and sentiment while preserving performance on off-target tasks. ActAdd takes far less compute and implementation effort than finetuning or RLHF, allows users control through natural language, and its computational overhead (as a fraction of inference time) appears stable or improving over increasing model size.},
  langid = {english},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\UWUCEGH9\\Turner et al. - 2024 - Activation Addition Steering Language Models Without Optimization.pdf;C\:\\Users\\janek\\Zotero\\storage\\D8I89JDU\\2308.html},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,generation steering,preprint,reading complete,recommended}
}

@online{tyoStateArtAuthorship2022,
  title = {On the State of the Art in Authorship Attribution and Authorship Verification},
  author = {Tyo, Jacob and Dhingra, Bhuwan and Lipton, Zachary C.},
  date = {2022-10-05},
  eprint = {2209.06869},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.2209.06869},
  url = {http://arxiv.org/abs/2209.06869},
  urldate = {2024-11-14},
  abstract = {Despite decades of research on authorship attribution (AA) and authorship verification (AV), inconsistent dataset splits/filtering and mismatched evaluation methods make it difficult to assess the state of the art. In this paper, we present a survey of the fields, resolve points of confusion, introduce Valla that standardizes and benchmarks AA/AV datasets and metrics, provide a large-scale empirical evaluation, and provide apples-to-apples comparisons between existing methods. We evaluate eight promising methods on fifteen datasets (including distribution-shifted challenge sets) and introduce a new large-scale dataset based on texts archived by Project Gutenberg. Surprisingly, we find that a traditional Ngram-based model performs best on 5 (of 7) AA tasks, achieving an average macro-accuracy of \$76.50\textbackslash\%\$ (compared to \$66.71\textbackslash\%\$ for a BERT-based model). However, on the two AA datasets with the greatest number of words per author, as well as on the AV datasets, BERT-based models perform best. While AV methods are easily applied to AA, they are seldom included as baselines in AA papers. We show that through the application of hard-negative mining, AV methods are competitive alternatives to AA methods. Valla and all experiment code can be found here: https://github.com/JacobTyo/Valla},
  langid = {english},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\XT7T7JGL\\Tyo et al. - 2022 - On the state of the art in authorship attribution and authorship verification.pdf;C\:\\Users\\janek\\Zotero\\storage\\VU9IKP5V\\2209.html},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,preprint}
}

@online{wangSelfinstructAligningLanguage2023,
  title = {Self-Instruct: Aligning Language Models with Self-Generated Instructions},
  shorttitle = {Self-Instruct},
  author = {Wang, Yizhong and Kordi, Yeganeh and Mishra, Swaroop and Liu, Alisa and Smith, Noah A. and Khashabi, Daniel and Hajishirzi, Hannaneh},
  date = {2023-05-25},
  eprint = {2212.10560},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.48550/arXiv.2212.10560},
  url = {http://arxiv.org/abs/2212.10560},
  urldate = {2024-09-29},
  abstract = {Large "instruction-tuned" language models (i.e., finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is often limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off their own generations. Our pipeline generates instructions, input, and output samples from a language model, then filters invalid or similar ones before using them to finetune the original model. Applying our method to the vanilla GPT3, we demonstrate a 33\% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT-001, which was trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with Self-Instruct outperforms using existing public instruction datasets by a large margin, leaving only a 5\% absolute gap behind InstructGPT-001. Self-Instruct provides an almost annotation-free method for aligning pre-trained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning. Our code and data are available at https://github.com/yizhongw/self-instruct.},
  langid = {english},
  pubstate = {prepublished},
  file = {C:\Users\janek\Zotero\storage\AHZEK9UN\Wang et al. - 2023 - Self-instruct aligning language models with self-generated instructions.pdf},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,preprint}
}

@inproceedings{wegmann-nguyen-2021-capture,
  title = {Does It Capture {{STEL}}? {{A}} Modular, Similarity-Based Linguistic Style Evaluation Framework},
  booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
  author = {Wegmann, Anna and Nguyen, Dong},
  editor = {Moens, Marie-Francine and Huang, Xuanjing and Specia, Lucia and Yih, Scott Wen-tau},
  date = {2021-11},
  pages = {7109--7130},
  publisher = {Association for Computational Linguistics},
  location = {Online and Punta Cana, Dominican Republic},
  doi = {10.18653/v1/2021.emnlp-main.569},
  url = {https://aclanthology.org/2021.emnlp-main.569},
  abstract = {Style is an integral part of natural language. However, evaluation methods for style measures are rare, often task-specific and usually do not control for content. We propose the modular, fine-grained and content-controlled similarity-based STyle EvaLuation framework (STEL) to test the performance of any model that can compare two sentences on style. We illustrate STEL with two general dimensions of style (formal/informal and simple/complex) as well as two specific characteristics of style (contrac'tion and numb3r substitution). We find that BERT-based methods outperform simple versions of commonly used style measures like 3-grams, punctuation frequency and LIWC-based approaches. We invite the addition of further tasks and task instances to STEL and hope to facilitate the improvement of style-sensitive measures.},
  langid = {english},
  keywords = {evaluation},
  file = {C:\Users\janek\Zotero\storage\RJYR7QVM\Wegmann und Nguyen - 2021 - Does It Capture S℡ A Modular, Similarity-based Linguistic Style Evaluation Framework.pdf}
}

@inproceedings{wegmannSameAuthorJust2022,
  title = {Same Author or Just Same Topic? {{Towards}} Content-Independent Style Representations},
  shorttitle = {Same Author or Just Same Topic?},
  booktitle = {Proceedings of the 7th {{Workshop}} on {{Representation Learning}} for {{NLP}}},
  author = {Wegmann, Anna and Schraagen, Marijn and Nguyen, Dong},
  editor = {Gella, Spandana and He, He and Majumder, Bodhisattwa Prasad and Can, Burcu and Giunchiglia, Eleonora and Cahyawijaya, Samuel and Min, Sewon and Mozes, Maximilian and Li, Xiang Lorraine and Augenstein, Isabelle and Rogers, Anna and Cho, Kyunghyun and Grefenstette, Edward and Rimell, Laura and Dyer, Chris},
  date = {2022-05},
  pages = {249--268},
  publisher = {Association for Computational Linguistics},
  location = {Dublin, Ireland},
  doi = {10.18653/v1/2022.repl4nlp-1.26},
  url = {https://aclanthology.org/2022.repl4nlp-1.26},
  urldate = {2024-11-14},
  abstract = {Linguistic style is an integral component of language. Recent advances in the development of style representations have increasingly used training objectives from authorship verification (AV)”:” Do two texts have the same author? The assumption underlying the AV training task (same author approximates same writing style) enables self-supervised and, thus, extensive training. However, a good performance on the AV task does not ensure good “general-purpose” style representations. For example, as the same author might typically write about certain topics, representations trained on AV might also encode content information instead of style alone. We introduce a variation of the AV training task that controls for content using conversation or domain labels. We evaluate whether known style dimensions are represented and preferred over content information through an original variation to the recently proposed S℡ framework. We find that representations trained by controlling for conversation are better than representations trained with domain or no content control at representing style independent from content.},
  eventtitle = {{{RepL4NLP}} 2022},
  langid = {english},
  keywords = {style transfer},
  file = {C:\Users\janek\Zotero\storage\GAYANL7F\Wegmann et al. - 2022 - Same Author or Just Same Topic Towards Content-Independent Style Representations.pdf}
}

@online{wolfHuggingFacesTransformersStateart2020,
  title = {{{HuggingFace}}'s {{Transformers}}: {{State-of-the-art Natural Language Processing}}},
  shorttitle = {{{HuggingFace}}'s {{Transformers}}},
  author = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Rémi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and family=Platen, given=Patrick, prefix=von, useprefix=false and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Scao, Teven Le and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
  date = {2020-07-14},
  eprint = {1910.03771},
  eprinttype = {arXiv},
  doi = {10.48550/arXiv.1910.03771},
  url = {http://arxiv.org/abs/1910.03771},
  urldate = {2024-11-04},
  abstract = {Recent progress in natural language processing has been driven by advances in both model architecture and model pretraining. Transformer architectures have facilitated building higher-capacity models and pretraining has made it possible to effectively utilize this capacity for a wide variety of tasks. \textbackslash textit\{Transformers\} is an open-source library with the goal of opening up these advances to the wider machine learning community. The library consists of carefully engineered state-of-the art Transformer architectures under a unified API. Backing this library is a curated collection of pretrained models made by and available for the community. \textbackslash textit\{Transformers\} is designed to be extensible by researchers, simple for practitioners, and fast and robust in industrial deployments. The library is available at \textbackslash url\{https://github.com/huggingface/transformers\}.},
  pubstate = {prepublished},
  file = {C\:\\Users\\janek\\Zotero\\storage\\XHYNAELR\\Wolf et al. - 2020 - HuggingFace's Transformers State-of-the-art Natural Language Processing.pdf;C\:\\Users\\janek\\Zotero\\storage\\QFT8ZTJN\\1910.html},
  keywords = {Computer Science - Computation and Language,preprint,programming_library}
}

@inproceedings{zhu-etal-2024-styleflow,
  title = {{{StyleFlow}}: Disentangle Latent Representations via Normalizing Flow for Unsupervised Text Style Transfer},
  booktitle = {Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation ({{LREC-COLING}} 2024)},
  author = {Zhu, Kangchen and Tian, Zhiliang and Wei, Jingyu and Luo, Ruifeng and Song, Yiping and Mao, Xiaoguang},
  editor = {Calzolari, Nicoletta and Kan, Min-Yen and Hoste, Veronique and Lenci, Alessandro and Sakti, Sakriani and Xue, Nianwen},
  date = {2024-05},
  pages = {15384--15397},
  publisher = {{ELRA and ICCL}},
  location = {Torino, Italia},
  url = {https://aclanthology.org/2024.lrec-main.1336},
  abstract = {Unsupervised text style transfer aims to modify the style of a sentence while preserving its content without parallel corpora. Existing approaches attempt to separate content from style, but some words contain both content and style information. It makes them difficult to disentangle, where unsatisfactory disentanglement results in the loss of the content information or the target style. To address this issue, researchers adopted a “cycle reconstruction” mechanism to maintain content information, but it is still hard to achieve satisfactory content preservation due to incomplete disentanglement. In this paper, we propose a new disentanglement-based method, StyleFlow, which effectively avoids the loss of contents through a better cycle reconstruction via a reversible encoder. The reversible encoder is a normalizing flow that can not only produce output given input but also infer the exact input given the output reversely. We design a stack of attention-aware coupling layers, where each layer is reversible and adopts the attention mechanism to improve the content-style disentanglement. Moreover, we propose a data augmentation method based on normalizing flow to enhance the training data. Our experiments on sentiment transfer and formality transfer tasks show that StyleFlow outperforms strong baselines on both content preservation and style transfer.},
  langid = {english},
  keywords = {style transfer}
}

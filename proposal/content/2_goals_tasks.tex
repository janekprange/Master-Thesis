% !TeX root = ..\Proposal.tex

\section{Thesis Goals and Tasks to Tackle Each Goal}
\subsection{Extract style attributes from data and train a style representation model}
This thesis is inspired heavily by \citet{patelLearningInterpretableStyle2023}. In their work, \citeauthor{patelLearningInterpretableStyle2023} use large language models (in their case ChatGPT) to extract style attributes in an unsupervised fashion. For each input text, the LLM is prompted around 90 times to describe the text with a focus on different linguistic features. The style descriptions are subsequently transformed into sentences of the form \enquote{The author uses x} or \enquote{The author is x} by prompting the LLM again. These sentences are the style attributes that form the dimensions of the interpretable style vectors.

By using the similarity between the sentence embeddings of the style attributes to find positive and negative example inputs for specific attributes, multiple models can be trained which produce an agreement score for one style attribute each. These models, which are called Style Feature Agreement Models (SFAM) in \citet{patelLearningInterpretableStyle2023}, are then used to annotate a larger set of data which is used as the basis to train a model that produces interpretable style vectors, where each dimension of the vector is a style attribute. The final model is called the Linguistically Interpretable Style Attribute (LISA) embedding model.

While the original method was used to differentiate the style from different authors, in my thesis I will use texts from different groups of people as the basis for my experiments. Differentiating group membership has some useful applications, especially in combination with the interpretable style vector since it can be used to understand which stylistic features different groups of people use when writing text. % TODO: more applications

SFAM and LISA will not be trained on all style attributes that will be extracted from the raw data, but on a selection of 768 attributes. This will be the size of the interpretable style vector as well. Since there will be a lot more attributes than that, I will take multiple steps to reduce their number and select the best ones.

Firstly, the style attributes will be clustered together with other attributes which have a sufficiently high SBERT-similarity. The style attribute at the center of each cluster will be the representation for the whole cluster. Subsequently, all attributes that have been used to describe more than \SI{60}{\percent} of the groups will be discarded since they are not useful to distinguish between the groups. Additionally, all attributes that were exclusively used for one group will be discarded as well since they are probably too group-specific and can not be generalized. From the remaining answers, the 768 most common attributes will be chosen.

In my thesis, I will use Llama3.2-3B-instruct %~\cite{dubeyLlama3Herd2024}
to extract the style descriptions and style attributes. The raw data that is the base for the synthetic dataset is taken from Stack Exchange and Reddit. The forums included in the dataset all have the theme that a specific group of people (i.e. old people, engineers, \ldots) are asked questions. Because of this, there is a high probability that the answers are written by these groups so that the style differences can be extracted.

The style representation model will be tested on unseen answers from the forums. The model will be tasked with predicting if answers are from the same group of people by just using the interpretable style vector. Additionally, the STEL framework~\cite{wegmann-nguyen-2021-capture} will be used to test the style representations against a human baseline.


\subsection{Compare the performance of the style representation model with and without knowledge attributes}
Knowledge Attributes, which encode the background knowledge and experience of the author, could potentially be useful to predict group membership in addition to style attributes. Therefore, I will implement the experiments from the previous section a second time with the difference that the knowledge attributes will be used in addition to the style attributes to train the SFAM and LISA models.

To test this method, I will compare the ability of the model to predict group membership with the model which has only access to style attributes. If however all knowledge attributes are discarded and only style attributes are chosen to be present in the interpretable style vector, it will be clear even without this test that the knowledge attributes show no significant improvement to predict group membership.


\subsection{Implement different methods to generate text in a specific style with the help of the interpretable style vectors.}
While it will be useful to have a model than can produce interpretable style vectors for arbitrary text, an important task that I will tackle in this thesis is to use the style vector to generate new text in a specific style. There are three different ways to reach this goal that I want to compare.
\begin{enumerate}
	\item Mention the group in the prompt (e.g. \enquote{Write the following explanation in the style of a teenager}). This is the baseline for all further experiments as the style vectors are not used. The style of the text generation can not be changed at a granular level, but it is very easy to implement.
	\item Use the dimensions/attributes of the interpretable style vector in the prompt. For this implementation, the most important style attributes for a group are included as part of the prompt to steer the output. This is fairly easy to implement and may give more control over the generation style than the first method.
	\item Use the style representation model to create training data to implement the ActAdd method presented in \citet{turnerActivationAdditionSteering2024}. ActAdd uses a bias added to one activation layer of the model to steer its output. This method has the advantage that it needs very little training data and works even with only one positive and one negative example. However, until now it has only been used to steer the output with regard to one attribute (e.g. \enquote{happy} vs. \enquote{sad}), not multiple as would be needed in the case of this thesis. Additionally, while it will be possible to select text from the dataset that are very similar or very dissimilar to a specific attribute, these text will have more differences than just this one attribute. This will increase the difficulty in extracting the steering vectors.
	      This is by far the most complex method, which is why it is not yet certain that it will be possible to fully implement it as part of the thesis. It is however the most promising method as it would give fine-grained control over the amount that each style attribute plays into the generated text.
\end{enumerate}

All methods will be tested by scoring the steered output with the SFAM model for the attribute that is the target for the steering. If the methods perform well, there should be a significant difference in the agreement score.



% \begin{itemize}
%   \item using the python libraries numpy~\cite{harris2020array}, pandas~\cite{reback2020pandas,mckinney-proc-scipy-2010}, pytorch~\cite{paszkePyTorchImperativeStyle2019}, transformers~\cite{wolfHuggingFacesTransformersStateart2020}, sentence-transformers~\cite{reimersSentenceBERTSentenceEmbeddings2019} and nltk~\cite{birdNaturalLanguageProcessing2009}
% \end{itemize}
